var documenterSearchIndex = {"docs":
[{"location":"controls/#Emissions-Controls","page":"Emissions Controls","title":"Emissions Controls","text":"","category":"section"},{"location":"controls/#Overview","page":"Emissions Controls","title":"Overview","text":"Emissions controls implement the SMOKE Cntlmat functionality for applying growth factors and control efficiencies to scale emissions. This enables scenario analysis, future-year projections, and regulatory compliance modeling.","category":"section"},{"location":"controls/#Usage","page":"Emissions Controls","title":"Usage","text":"","category":"section"},{"location":"controls/#Growth-Factors","page":"Emissions Controls","title":"Growth Factors","text":"Growth factors project emissions from a base year to a target year:\n\nusing Emissions\n\ncontrols = read_growth_factors(\"path/to/growth_factors.txt\")\nprojected = apply_controls(emissions, controls)","category":"section"},{"location":"controls/#Control-Factors","page":"Emissions Controls","title":"Control Factors","text":"Control factors apply efficiency/effectiveness/penetration reductions:\n\ncontrols = read_control_factors(\"path/to/control_factors.txt\")\ncontrolled = apply_controls(emissions, controls)","category":"section"},{"location":"controls/#Combined-Controls","page":"Emissions Controls","title":"Combined Controls","text":"Growth and multiplicative controls can be combined. Growth is applied first, then multiplicative:\n\ngrowth = read_growth_factors(\"growth.txt\")\nmult = read_control_factors(\"control.txt\")\nall_controls = vcat(growth, mult)\nresult = apply_controls(emissions, all_controls)","category":"section"},{"location":"controls/#File-Formats","page":"Emissions Controls","title":"File Formats","text":"","category":"section"},{"location":"controls/#Growth-Factor-File","page":"Emissions Controls","title":"Growth Factor File","text":"Semicolon-delimited: FIPS;SCC;pollutant;base_year;target_year;growth_factor","category":"section"},{"location":"controls/#Control-Factor-File","page":"Emissions Controls","title":"Control Factor File","text":"Semicolon-delimited: FIPS;SCC;pollutant;efficiency;effectiveness;penetration\n\nThe multiplicative factor is: 1 - (efficiency/100 * effectiveness/100 * penetration/100)","category":"section"},{"location":"controls/#Hierarchical-Matching","page":"Emissions Controls","title":"Hierarchical Matching","text":"Control matching uses a 7-level hierarchy from most specific to least:\n\nExact FIPS + SCC + pollutant\nExact FIPS + SCC (any pollutant)\nExact FIPS + pollutant (any SCC)\nExact FIPS only\nNational default + SCC + pollutant\nNational default + pollutant\nNational default only","category":"section"},{"location":"controls/#Emissions.ControlSpec","page":"Emissions Controls","title":"Emissions.ControlSpec","text":"ControlSpec\n\nSpecification for an emissions control or growth factor.\n\nFields\n\nregion::String: Country or region code\nfips::String: 5-digit FIPS code (\"00000\" for national default)\nscc::String: Source Classification Code (\"0000000000\" for any SCC)\npollutant::String: Pollutant name (\"\" for all pollutants)\ncontrol_type::Symbol: :growth, :multiplicative, or :reactivity\nfactor::Float64: Multiplicative factor to apply to emissions\nbase_year::Int: Base year of the inventory\ntarget_year::Int: Target year for projection\n\n\n\n\n\n","category":"type"},{"location":"controls/#Emissions.read_growth_factors","page":"Emissions Controls","title":"Emissions.read_growth_factors","text":"read_growth_factors(filepath::AbstractString) -> Vector{ControlSpec}\n\nRead a SMOKE-format growth factor file.\n\nLines starting with # are skipped. Each data line has semicolon-delimited fields: FIPS;SCC;pollutant;base_year;target_year;growth_factor\n\nGrowth factors are applied multiplicatively: new_value = old_value * growth_factor.\n\nReturns\n\nA Vector{ControlSpec} with control_type = :growth.\n\n\n\n\n\n","category":"function"},{"location":"controls/#Emissions.read_control_factors","page":"Emissions Controls","title":"Emissions.read_control_factors","text":"read_control_factors(filepath::AbstractString) -> Vector{ControlSpec}\n\nRead a SMOKE-format multiplicative control factor file.\n\nLines starting with # are skipped. Each data line has semicolon-delimited fields: FIPS;SCC;pollutant;efficiency;effectiveness;penetration\n\nThe multiplicative control factor is computed as: factor = 1 - (efficiency/100 * effectiveness/100 * penetration/100)\n\nReturns\n\nA Vector{ControlSpec} with control_type = :multiplicative.\n\n\n\n\n\n","category":"function"},{"location":"controls/#Emissions.apply_controls","page":"Emissions Controls","title":"Emissions.apply_controls","text":"apply_controls(emissions::DataFrame, controls::Vector{ControlSpec}) -> DataFrame\n\nApply emissions controls to scale ANN_VALUE.\n\nGrowth factors are applied first (multiplicative), then multiplicative controls. The combined factor is: new_ANN_VALUE = ANN_VALUE * growth_factor * control_factor.\n\nArguments\n\nemissions::DataFrame: Must have columns :FIPS, :SCC, :POLID, :ANN_VALUE.\ncontrols::Vector{ControlSpec}: Control specifications from read_growth_factors and/or read_control_factors.\n\nReturns\n\nA copy of emissions with ANN_VALUE adjusted by matching control factors.\n\n\n\n\n\n","category":"function"},{"location":"laypoint/#Vertical-Layer-Allocation","page":"Vertical Layer Allocation","title":"Vertical Layer Allocation","text":"","category":"section"},{"location":"laypoint/#Overview","page":"Vertical Layer Allocation","title":"Overview","text":"Vertical layer allocation implements the SMOKE Laypoint functionality. It distributes elevated point source emissions across vertical atmospheric layers using meteorological data and the ASME (1973) plume rise calculation.","category":"section"},{"location":"laypoint/#Usage","page":"Vertical Layer Allocation","title":"Usage","text":"","category":"section"},{"location":"laypoint/#Basic-Layer-Allocation","page":"Vertical Layer Allocation","title":"Basic Layer Allocation","text":"using Emissions\n\n# Define atmospheric layers (staggered heights in meters)\nconfig = LayerConfig([0.0, 100.0, 500.0, 1000.0, 2000.0, 5000.0])\n\n# Define meteorological profile\nmet = MetProfile(\n    fill(280.0, 5),    # temperature per layer (K)\n    fill(5.0, 5),      # wind speed per layer (m/s)\n    fill(0.0, 5),      # stability class (0=unstable)\n    fill(0.0, 5),      # stability parameter\n)\nmet_profiles = Dict(\"default\" => met)\n\n# Allocate point sources to layers\nresult = laypoint(point_emissions, met_profiles, config)","category":"section"},{"location":"laypoint/#Integration-with-Merge","page":"Vertical Layer Allocation","title":"Integration with Merge","text":"The output from laypoint includes :layer and :layer_fraction columns that are automatically handled by merge_emissions when present, producing 3D gridded emissions with layer information.","category":"section"},{"location":"laypoint/#Algorithm","page":"Vertical Layer Allocation","title":"Algorithm","text":"For each point source, compute ASME (1973) plume rise using stack parameters and meteorological data\nDetermine plume bottom (stack height) and plume top (stack + rise + spread)\nDistribute the plume across layers proportionally to overlap height\nLayer fractions sum to 1.0 for each source\nPlumes above model top are allocated to the top layer","category":"section"},{"location":"laypoint/#Emissions.LayerConfig","page":"Vertical Layer Allocation","title":"Emissions.LayerConfig","text":"LayerConfig\n\nConfiguration for vertical atmospheric layers.\n\nFields\n\nlayer_heights::Vector{Float64}: Staggered layer interface heights in meters (n+1 values for n layers). First value is surface (usually 0.0), last is model top.\nn_layers::Int: Number of atmospheric layers.\n\n\n\n\n\n","category":"type"},{"location":"laypoint/#Emissions.MetProfile","page":"Vertical Layer Allocation","title":"Emissions.MetProfile","text":"MetProfile\n\nMeteorological profile data for vertical layer allocation.\n\nAll vectors should have length equal to the number of layers.\n\nFields\n\ntemperature::Vector{Float64}: Temperature at each layer center (K)\nwind_speed::Vector{Float64}: Wind speed at each layer center (m/s)\nstability_class::Vector{Float64}: Stability class (0=unstable, >0.5=stable)\nstability_param::Vector{Float64}: Stability parameter s1 for plume rise\n\n\n\n\n\n","category":"type"},{"location":"laypoint/#Emissions.compute_layer_fractions","page":"Vertical Layer Allocation","title":"Emissions.compute_layer_fractions","text":"compute_layer_fractions(plume_bottom::Float64, plume_top::Float64,\n    config::LayerConfig) -> Vector{Float64}\n\nCompute the fraction of a plume within each atmospheric layer using pressure-weighted allocation.\n\nThe plume is assumed to be uniformly distributed between plume_bottom and plume_top. The fraction in each layer is proportional to the overlap height between the plume and that layer.\n\nFractions sum to 1.0. If the plume extends above the model top, the excess is allocated to the top layer.\n\nArguments\n\nplume_bottom: Bottom of the plume (m), typically the stack height.\nplume_top: Top of the plume (m), stack height + plume rise.\nconfig: Layer configuration.\n\nReturns\n\nA Vector{Float64} of length config.n_layers with layer fractions summing to 1.0.\n\n\n\n\n\n","category":"function"},{"location":"laypoint/#Emissions.allocate_point_to_layers","page":"Vertical Layer Allocation","title":"Emissions.allocate_point_to_layers","text":"allocate_point_to_layers(height, diam, temp, vel, met::MetProfile,\n    config::LayerConfig; spread::Float64=0.5) -> Vector{Float64}\n\nCompute layer fractions for a single point source using ASME plume rise.\n\nCalculates plume rise using the existing ASME algorithm with the provided meteorological profile, then distributes the plume across layers using compute_layer_fractions.\n\nThe plume is distributed over a range from stack_height to stack_height + plume_rise + spread * plume_rise.\n\nArguments\n\nheight: Stack height (m)\ndiam: Stack diameter (m)\ntemp: Stack exit temperature (K)\nvel: Stack exit velocity (m/s)\nmet::MetProfile: Meteorological profile for the source location.\nconfig::LayerConfig: Layer configuration.\nspread::Float64=0.5: Plume spread factor (fraction of plume rise added above center).\n\nReturns\n\nLayer fractions as Vector{Float64} summing to 1.0.\n\n\n\n\n\n","category":"function"},{"location":"laypoint/#Emissions.laypoint","page":"Vertical Layer Allocation","title":"Emissions.laypoint","text":"laypoint(point_emissions::DataFrame, met_profiles::Dict{String, MetProfile},\n    config::LayerConfig) -> DataFrame\n\nAllocate point source emissions to vertical atmospheric layers.\n\nFor each point source, computes plume rise using the ASME algorithm and distributes emissions across layers. Sources without meteorological data are placed in the surface layer.\n\nArguments\n\npoint_emissions::DataFrame: Must have columns :STKHGT, :STKDIAM, :STKTEMP, :STKVEL, :FIPS. May have :LONGITUDE, :LATITUDE.\nmet_profiles::Dict{String, MetProfile}: Meteorological profiles keyed by location key (see location_key). A key of \"default\" is used as fallback.\nconfig::LayerConfig: Layer configuration.\n\nReturns\n\nA DataFrame with all original columns plus:\n\n:layer (Int): Layer index (1-based)\n:layer_fraction (Float64): Fraction of emissions in this layer\n\nEach input row may produce multiple output rows (one per layer with non-zero fraction).\n\n\n\n\n\n","category":"function"},{"location":"laypoint/#Emissions.ASME","page":"Vertical Layer Allocation","title":"Emissions.ASME","text":"ASME(stackHeight, stackDiam, stackTemp, stackVel, layerHeights,\n     temperature, windSpeed, sClass, s1) -> (plumeLayer, plumeHeight)\n\nCalculate the effective emissions height after accounting for plume rise using the ASME (1973) algorithm, as described in Seinfeld and Pandis, \"Atmospheric Chemistry and Physics - From Air Pollution to Climate Change\".\n\nArguments\n\nstackHeight: Stack height (m)\nstackDiam: Stack diameter (m)\nstackTemp: Stack exit temperature (K)\nstackVel: Stack exit velocity (m/s)\nlayerHeights: Model layer interface heights (staggered grid, m)\ntemperature: Temperature at each layer (K, unstaggered grid)\nwindSpeed: Wind speed at each layer (m/s, unstaggered grid)\nsClass: Stability class at each layer (0=unstable, >0.5=stable)\ns1: Stability parameter at each layer\n\nReturns\n\nA tuple (plumeLayer, plumeHeight) where plumeLayer is the layer index containing the plume top and plumeHeight is the effective plume height (m).\n\n\n\n\n\n","category":"function"},{"location":"reporting/#QA-Reporting","page":"QA Reporting","title":"QA Reporting","text":"","category":"section"},{"location":"reporting/#Overview","page":"QA Reporting","title":"Overview","text":"The QA reporting module provides summary statistics and comparison tools for emissions data, analogous to SMOKE's Smkreport utility. Reports can be generated from both pre-merge inventory data and post-merge gridded emissions.","category":"section"},{"location":"reporting/#Usage","page":"QA Reporting","title":"Usage","text":"","category":"section"},{"location":"reporting/#Summary-by-Pollutant","page":"QA Reporting","title":"Summary by Pollutant","text":"using Emissions, DataFrames\n\n# Pre-merge inventory data\ninventory = DataFrame(\n    FIPS = [\"36001\", \"36001\", \"36005\", \"06001\"],\n    SCC = [\"2103007000\", \"2103007000\", \"2103007001\", \"2103007000\"],\n    POLID = [\"NOX\", \"NOX\", \"VOC\", \"NOX\"],\n    ANN_VALUE = [100.0, 50.0, 200.0, 75.0]\n)\n\nsummary_by_pollutant(inventory)","category":"section"},{"location":"reporting/#Summary-by-SCC","page":"QA Reporting","title":"Summary by SCC","text":"summary_by_scc(inventory)","category":"section"},{"location":"reporting/#Inventory-Comparison","page":"QA Reporting","title":"Inventory Comparison","text":"# Compare base and scenario inventories\nbase = DataFrame(\n    FIPS = [\"36001\", \"36005\"],\n    SCC = [\"2103007000\", \"2103007001\"],\n    POLID = [\"NOX\", \"VOC\"],\n    ANN_VALUE = [100.0, 200.0]\n)\n\nscenario = DataFrame(\n    FIPS = [\"36001\", \"36005\"],\n    SCC = [\"2103007000\", \"2103007001\"],\n    POLID = [\"NOX\", \"VOC\"],\n    ANN_VALUE = [80.0, 210.0]\n)\n\ncompare_inventories(base, scenario)","category":"section"},{"location":"reporting/#Custom-Reports","page":"QA Reporting","title":"Custom Reports","text":"config = ReportConfig(group_by = [:FIPS, :POLID], top_n = 5)\nemissions_report(inventory; config = config)","category":"section"},{"location":"reporting/#Time-Series-Reports-(Post-Merge)","page":"QA Reporting","title":"Time Series Reports (Post-Merge)","text":"using Dates\n\ngridded = DataFrame(\n    grid_row = [1, 1, 1, 1],\n    grid_col = [1, 1, 1, 1],\n    hour = [DateTime(2019, 7, 1, 0), DateTime(2019, 7, 1, 12),\n            DateTime(2019, 7, 2, 0), DateTime(2019, 7, 2, 12)],\n    pollutant = [\"NOX\", \"NOX\", \"NOX\", \"NOX\"],\n    emission_rate = [100.0, 150.0, 90.0, 140.0]\n)\n\nsummary_by_time(gridded; resolution = :daily)","category":"section"},{"location":"reporting/#Emissions.ReportConfig","page":"QA Reporting","title":"Emissions.ReportConfig","text":"ReportConfig\n\nConfiguration for emissions summary reports.\n\nFields\n\ngroup_by::Vector{Symbol}: Columns to group by (e.g., [:FIPS, :POLID]).\ntime_resolution::Symbol: Temporal aggregation level (:hourly, :daily, :monthly, :annual).\ntop_n::Int: Number of top entries to include (0 for all).\n\n\n\n\n\n","category":"type"},{"location":"reporting/#Emissions.summary_by_pollutant","page":"QA Reporting","title":"Emissions.summary_by_pollutant","text":"summary_by_pollutant(emissions::DataFrame) -> DataFrame\n\nCompute total, mean, and maximum emission values per pollutant.\n\nExpects a DataFrame with at least :POLID and :ANN_VALUE columns (pre-merge inventory) or :pollutant and :emission_rate columns (post-merge gridded data).\n\nReturns a DataFrame with columns: :pollutant, :total, :mean, :max, :count.\n\n\n\n\n\n","category":"function"},{"location":"reporting/#Emissions.summary_by_region","page":"QA Reporting","title":"Emissions.summary_by_region","text":"summary_by_region(emissions::DataFrame,\n    region_map::Dict{Tuple{Int,Int}, String}) -> DataFrame\n\nCompute total emissions per region and pollutant for gridded data.\n\nregion_map maps (grid_row, grid_col) to a region name string.\n\nReturns a DataFrame with columns: :region, :pollutant, :total.\n\n\n\n\n\n","category":"function"},{"location":"reporting/#Emissions.summary_by_scc","page":"QA Reporting","title":"Emissions.summary_by_scc","text":"summary_by_scc(emissions::DataFrame) -> DataFrame\n\nCompute total emissions per SCC code and pollutant from pre-merge inventory data.\n\nExpects columns :SCC, :POLID, :ANN_VALUE.\n\nReturns a DataFrame with columns: :SCC, :POLID, :total, :count, sorted by total descending.\n\n\n\n\n\n","category":"function"},{"location":"reporting/#Emissions.summary_by_time","page":"QA Reporting","title":"Emissions.summary_by_time","text":"summary_by_time(emissions::DataFrame; resolution::Symbol=:daily) -> DataFrame\n\nAggregate gridded hourly emissions by time period.\n\nresolution must be :hourly, :daily, or :monthly.\n\nReturns a DataFrame with columns: :period, :pollutant, :total.\n\n\n\n\n\n","category":"function"},{"location":"reporting/#Emissions.compare_inventories","page":"QA Reporting","title":"Emissions.compare_inventories","text":"compare_inventories(base::DataFrame, scenario::DataFrame;\n    join_on::Vector{Symbol}=[:FIPS, :SCC, :POLID]) -> DataFrame\n\nCompare two emission inventories and compute absolute and percent differences.\n\nBoth DataFrames must have join_on columns plus :ANN_VALUE.\n\nReturns a DataFrame with columns from join_on plus: :base_value, :scenario_value, :abs_diff, :pct_diff.\n\n\n\n\n\n","category":"function"},{"location":"reporting/#Emissions.emissions_report","page":"QA Reporting","title":"Emissions.emissions_report","text":"emissions_report(emissions::DataFrame; config::ReportConfig=ReportConfig()) -> DataFrame\n\nGenerate a summary report grouped by the specified columns.\n\nUses config.group_by for grouping, applies config.top_n limit if > 0. Works with both pre-merge (:POLID, :ANN_VALUE) and post-merge (:pollutant, :emission_rate) DataFrames.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Spatial-Processing-Pipeline","page":"Spatial Processing Pipeline","title":"Spatial Processing Pipeline","text":"","category":"section"},{"location":"spatial_processing/#Overview","page":"Spatial Processing Pipeline","title":"Overview","text":"The Emissions.jl package provides a complete spatial processing pipeline for allocating emissions to grid cells, implementing the workflow from the 2019 NEI emissions processing notebook.\n\nThe pipeline consists of two layers:\n\nData Preparation: Reading FF10 files, aggregating emissions, filtering pollutants, mapping names, and assigning spatial surrogates.\nSpatial Allocation: Computing grid cell indices for emission locations, optionally refining with surrogate-weighted fractions, and distributing emissions to grid cells.","category":"section"},{"location":"spatial_processing/#Data-Preparation-Functions","page":"Spatial Processing Pipeline","title":"Data Preparation Functions","text":"","category":"section"},{"location":"spatial_processing/#File-I/O","page":"Spatial Processing Pipeline","title":"File I/O","text":"","category":"section"},{"location":"spatial_processing/#Emissions-Processing","page":"Spatial Processing Pipeline","title":"Emissions Processing","text":"","category":"section"},{"location":"spatial_processing/#Surrogate-Assignment","page":"Spatial Processing Pipeline","title":"Surrogate Assignment","text":"","category":"section"},{"location":"spatial_processing/#Spatial-Allocation-Functions","page":"Spatial Processing Pipeline","title":"Spatial Allocation Functions","text":"","category":"section"},{"location":"spatial_processing/#High-Level-Workflow-Functions","page":"Spatial Processing Pipeline","title":"High-Level Workflow Functions","text":"","category":"section"},{"location":"spatial_processing/#Low-Level-Surrogate-Generation-Functions","page":"Spatial Processing Pipeline","title":"Low-Level Surrogate Generation Functions","text":"The following low-level functions are used for advanced surrogate generation from shapefiles. For complete API documentation, see the NEI Processing page.\n\ngenerate_data_sparse_matrices - Generate sparse matrices from data shapefiles\ngenerate_weight_sparse_matrices - Generate weight matrices from surrogate shapefiles\ngenerate_grid_sparse_matrices - Generate grid area matrices\ngenerate_countySurrogate - Combine data and weight matrices into normalized surrogates\nupdate_locIndex - Update location indices with surrogate data","category":"section"},{"location":"spatial_processing/#Implementation","page":"Spatial Processing Pipeline","title":"Implementation","text":"","category":"section"},{"location":"spatial_processing/#Complete-Workflow-Example","page":"Spatial Processing Pipeline","title":"Complete Workflow Example","text":"The following example demonstrates the full spatial processing pipeline using synthetic data. This corresponds to the workflow in the reference notebook.\n\nusing Emissions\nusing DataFrames\nusing SparseArrays\n\n# =============================================================================\n# Step 1: Create Synthetic Emissions Data\n# =============================================================================\n# Simulating two emission sectors with point source coordinates\nnonpoint_data = DataFrame(\n    POLID = [\"NOX\", \"VOC\", \"NOX\", \"SO2\"],\n    COUNTRY = [\"USA\", \"USA\", \"USA\", \"USA\"],\n    FIPS = [\"36001\", \"36001\", \"36005\", \"36005\"],\n    SCC = [\"2103007000\", \"2103007000\", \"2103007000\", \"2103007000\"],\n    ANN_VALUE = [150.5, 75.2, 200.1, 125.8]\n)\n\nonroad_data = DataFrame(\n    POLID = [\"NOX\", \"EXH__VOC\", \"PM25-PRI\"],\n    COUNTRY = [\"USA\", \"USA\", \"USA\"],\n    FIPS = [\"36001\", \"36001\", \"36005\"],\n    SCC = [\"2201001000\", \"2201001000\", \"2201001000\"],\n    ANN_VALUE = [50.0, 30.0, 15.0]\n)\n\nprintln(\"Nonpoint records: \", nrow(nonpoint_data))\nprintln(\"Onroad records: \", nrow(onroad_data))\n\n# =============================================================================\n# Step 2: Aggregate Emissions from Multiple Sectors\n# =============================================================================\ncombined = aggregate_emissions([nonpoint_data, onroad_data])\nprintln(\"Combined records: \", nrow(combined))\nfirst(combined, 5)\n\n# =============================================================================\n# Step 3: Filter to Known Pollutants and Map Names\n# =============================================================================\nfiltered = filter_known_pollutants(combined)\nprintln(\"After filtering: \", nrow(filtered))\n\nmap_pollutant_names!(filtered)\nprintln(\"Unique pollutants: \", unique(filtered.POLID))\n\n# =============================================================================\n# Step 4: Assign Spatial Surrogates\n# =============================================================================\ngridref = DataFrame(\n    COUNTRY = [\"USA\", \"USA\", \"USA\"],\n    FIPS = [\"36001\", \"36005\", \"00000\"],\n    SCC = [\"2103007000\", \"2103007000\", \"2201001000\"],\n    Surrogate = [100, 100, 200]\n)\n\nwith_surrogates = assign_surrogates(filtered, gridref)\nprintln(\"Surrogates assigned: \", count(!ismissing, with_surrogates.Surrogate),\n    \" of \", nrow(with_surrogates))\n\n# =============================================================================\n# Step 5: Create Target Grid\n# =============================================================================\n# Create a simple 4x4 grid (in real use, this would be an InMAP or CMAQ grid)\ngrid = NewGridIrregular(\"CONUS_4x4\", 4, 4, \"EPSG:4326\", 1.0, 1.0, -76.0, 39.0)\nprintln(\"Grid: $(grid.Nx) x $(grid.Ny) = $(grid.Nx * grid.Ny) cells\")\n\n# =============================================================================\n# Step 6: Spatial Allocation with Surrogates\n# =============================================================================\n# Create synthetic county surrogates that distribute emissions across grid cells.\n# In real use, these are generated by generate_data_sparse_matrices(),\n# generate_weight_sparse_matrices(), and generate_countySurrogate().\n\n# County 36001 (Albany, NY): 60% in cell (1,1), 40% in cell (1,2)\nsrg_36001 = sparse([1, 1], [1, 2], [0.6, 0.4], 4, 4)\n\n# County 36005 (Bronx, NY): 50% in cell (2,1), 30% in cell (2,2), 20% in cell (3,1)\nsrg_36005 = sparse([2, 2, 3], [1, 2, 1], [0.5, 0.3, 0.2], 4, 4)\n\ncounty_surrogates = Dict(\"36001\" => srg_36001, \"36005\" => srg_36005)\n\n# Run the complete spatial allocation workflow\ngridded = process_emissions_spatial(with_surrogates, grid;\n    county_surrogates=county_surrogates)\n\nprintln(\"Gridded output: $(nrow(gridded)) rows\")\ngridded","category":"section"},{"location":"spatial_processing/#Step-by-Step-Spatial-Allocation","page":"Spatial Processing Pipeline","title":"Step-by-Step Spatial Allocation","text":"The process_emissions_spatial function orchestrates three steps that can also be called individually for more control:\n\n# Step 6a: Compute grid indices for all unique locations\nlocIndex = compute_grid_indices(with_surrogates, grid)\nprintln(\"Location indices computed: \", length(locIndex))\nfor (key, idx) in locIndex\n    println(\"  $key: inGrid=$(idx.inGrid), cells=$(length(idx.rows))\")\nend\n\n# Step 6b: Refine area-source indices with surrogate data\nrefine_indices_with_surrogates(locIndex, county_surrogates)\nprintln(\"\\nAfter surrogate refinement:\")\nfor (key, idx) in locIndex\n    println(\"  $key: inGrid=$(idx.inGrid), cells=$(length(idx.rows))\")\n    if idx.inGrid\n        for k in eachindex(idx.rows)\n            println(\"    cell($(idx.rows[k]),$(idx.cols[k])): $(round(idx.fracs[k]*100, digits=1))%\")\n        end\n    end\nend\n\n# Step 6c: Allocate emissions to grid cells\ngridded_manual = allocate_emissions_to_grid(with_surrogates, locIndex, grid)\nprintln(\"Manual allocation result: $(nrow(gridded_manual)) rows\")\ngridded_manual","category":"section"},{"location":"spatial_processing/#Point-Source-Processing","page":"Spatial Processing Pipeline","title":"Point Source Processing","text":"Point sources with coordinates are allocated directly to their containing grid cell:\n\n# Point source emissions with explicit coordinates\npoint_emissions = DataFrame(\n    FIPS = [\"36001\", \"36001\"],\n    POLID = [\"NOX\", \"VOC\"],\n    SCC = [\"2103007000\", \"2103007000\"],\n    ANN_VALUE = [1.0e-3, 5.0e-4],\n    LONGITUDE = [-75.5, -75.5],\n    LATITUDE = [39.5, 39.5]\n)\n\npoint_result = process_emissions_spatial(point_emissions, grid)\nprintln(\"Point source allocation:\")\npoint_result","category":"section"},{"location":"spatial_processing/#Analysis","page":"Spatial Processing Pipeline","title":"Analysis","text":"","category":"section"},{"location":"spatial_processing/#Surrogate-Assignment-with-Fallback","page":"Spatial Processing Pipeline","title":"Surrogate Assignment with Fallback","text":"The assign_surrogates function implements a two-pass matching strategy:\n\nDirect match: Joins emissions with grid reference on (COUNTRY, FIPS, SCC)\nFallback match: For unmatched records, retries with FIPS=\"00000\" (state-level default)\n\nThis ensures that emissions records always get a surrogate assignment when a default is available, even if the specific county-level entry is missing from the grid reference.\n\n# Demonstrate fallback: FIPS 36999 is not in gridref, but \"00000\" provides a default\ntest_emissions = DataFrame(\n    POLID = [\"NOX\", \"NOX\"],\n    COUNTRY = [\"USA\", \"USA\"],\n    FIPS = [\"36001\", \"36999\"],\n    SCC = [\"2103007000\", \"2103007000\"],\n    ANN_VALUE = [100.0, 50.0]\n)\ntest_gridref = DataFrame(\n    COUNTRY = [\"USA\", \"USA\"],\n    FIPS = [\"36001\", \"00000\"],\n    SCC = [\"2103007000\", \"2103007000\"],\n    Surrogate = [100, 300]\n)\nresult = assign_surrogates(test_emissions, test_gridref)\nprintln(\"FIPS 36001 surrogate: \", result[result.FIPS .== \"36001\", :Surrogate][1])\nprintln(\"FIPS 36999 surrogate (fallback): \", result[result.FIPS .== \"36999\", :Surrogate][1])\nprintln(\"FIPS 36999 preserved: \", result[result.FIPS .== \"36999\", :FIPS][1])","category":"section"},{"location":"spatial_processing/#Emissions-Conservation","page":"Spatial Processing Pipeline","title":"Emissions Conservation","text":"A key property of the spatial allocation is that total emissions are conserved. The surrogate fractions are normalized to sum to 1.0 for each county, ensuring that distributing emissions across grid cells preserves the total:\n\n# Verify conservation: total emissions in == total emissions out\ninput_nox = sum(filter(r -> r.POLID == \"NOX\", with_surrogates).ANN_VALUE)\noutput_nox = sum(gridded.NOX)\nprintln(\"Input NOX total:  \", round(input_nox, digits=4))\nprintln(\"Output NOX total: \", round(output_nox, digits=4))\nprintln(\"Conservation: \", isapprox(input_nox, output_nox, rtol=1e-10) ? \"PASS\" : \"FAIL\")","category":"section"},{"location":"spatial_processing/#Country-Code-Normalization","page":"Spatial Processing Pipeline","title":"Country Code Normalization","text":"The normalize_country function handles the various country code formats found in different data sources:\n\ncodes = [\"US\", \"0\", \"1\", \"2\", \"USA\", \"Canada\"]\nfor code in codes\n    println(\"\\\"$code\\\" => \\\"$(normalize_country(code))\\\"\")\nend","category":"section"},{"location":"spatial_processing/#Advanced-Surrogate-Generation","page":"Spatial Processing Pipeline","title":"Advanced Surrogate Generation","text":"For more complex spatial allocation scenarios, you can generate surrogate matrices directly from shapefiles using the low-level surrogate generation functions. This example demonstrates how to create county surrogates from census and employment data:\n\n# =============================================================================\n# Step 7: Advanced Surrogate Generation from Shapefiles\n# =============================================================================\n# This demonstrates the workflow for generating surrogates when you have\n# county polygons and weight data (e.g., population, employment) shapefiles\n\nprintln(\"Advanced surrogate generation workflow:\")\nprintln(\"1. Generate county polygon matrices using:\")\nprintln(\"   data_matrices = generate_data_sparse_matrices(\")\nprintln(\"       \\\"counties.shp\\\", \\\"FIPS\\\", grid, \\\"EPSG:4326\\\")\")\nprintln()\nprintln(\"2. Generate weight matrices (e.g., from census blocks) using:\")\nprintln(\"   weight_matrix = generate_weight_sparse_matrices(\")\nprintln(\"       \\\"census_blocks.shp\\\", [\\\"POPULATION\\\"], [1.0], grid, \\\"EPSG:4326\\\")\")\nprintln()\nprintln(\"3. Generate grid matrices for normalization using:\")\nprintln(\"   grid_matrix = generate_grid_sparse_matrices(grid)\")\nprintln()\nprintln(\"4. Combine into county-level surrogates using:\")\nprintln(\"   county_surrogates = generate_countySurrogate(\")\nprintln(\"       data_matrices, weight_matrix, grid_matrix)\")\nprintln()\n\n# For demonstration, we'll show the expected data structure:\nprintln(\"Example surrogate matrix structure:\")\nexample_matrix = sparse([1, 1, 2], [1, 2, 1], [0.6, 0.4, 1.0], 4, 4)\nprintln(\"Matrix dimensions: \", size(example_matrix))\nprintln(\"Non-zero entries: \", nnz(example_matrix))\nprintln(\"Row sums: \", [sum(example_matrix[i, :]) for i in 1:size(example_matrix, 1)])\n\n# =============================================================================\n# Step 8: Complete End-to-End Workflow with Manual Surrogate Creation\n# =============================================================================\n# This demonstrates creating surrogates programmatically without shapefiles\n# (useful for testing and when actual shapefile data is not available)\n\nprintln(\"Creating synthetic surrogate data for complete workflow demonstration:\")\n\n# Simulate data matrices (county polygons)\n# In real use, these come from generate_data_sparse_matrices()\nprintln(\"1. Simulating data matrices (county coverage):\")\ndata_matrices = Dict{String, SparseMatrixCSC{Float64,Int}}()\ndata_matrices[\"36001\"] = sparse([1, 1, 2], [1, 2, 2], [0.8, 0.3, 0.5], 4, 4)  # Albany county\ndata_matrices[\"36005\"] = sparse([2, 3, 3], [1, 1, 2], [0.7, 0.4, 0.6], 4, 4)  # Bronx county\nprintln(\"   County 36001 covers \", nnz(data_matrices[\"36001\"]), \" grid cells\")\nprintln(\"   County 36005 covers \", nnz(data_matrices[\"36005\"]), \" grid cells\")\n\n# Simulate weight matrix (population distribution)\n# In real use, this comes from generate_weight_sparse_matrices()\nprintln(\"\\n2. Simulating weight matrix (population distribution):\")\nweight_matrix = sparse([1, 1, 2, 2, 3, 3], [1, 2, 1, 2, 1, 2],\n                      [1000.0, 800.0, 1500.0, 1200.0, 600.0, 900.0], 4, 4)\nprintln(\"   Population weight matrix has \", nnz(weight_matrix), \" populated cells\")\n\n# Generate grid matrix\n# In real use, this comes from generate_grid_sparse_matrices()\nprintln(\"\\n3. Generating grid matrix (cell areas):\")\ngrid_matrix = generate_grid_sparse_matrices(grid)\nprintln(\"   Grid matrix covers \", nnz(grid_matrix), \" cells\")\n\n# Generate county surrogates using the implemented function\nprintln(\"\\n4. Generating county surrogates:\")\ncounty_surrogates_full = generate_countySurrogate(data_matrices, weight_matrix, grid_matrix)\nprintln(\"   Generated surrogates for \", length(county_surrogates_full), \" counties\")\n\nfor (county, surrogate) in county_surrogates_full\n    total = sum(surrogate)\n    println(\"   County $county: $(nnz(surrogate)) cells, total weight = $(round(total, digits=6))\")\nend\n\n# Now use these surrogates in the workflow\nprintln(\"\\n5. Running spatial allocation with generated surrogates:\")\nfinal_result = process_emissions_spatial(with_surrogates, grid;\n    county_surrogates=county_surrogates_full)\n\nprintln(\"Final gridded emissions:\")\nfinal_result","category":"section"},{"location":"spatial_processing/#Relationship-to-Reference-Workflow","page":"Spatial Processing Pipeline","title":"Relationship to Reference Workflow","text":"These functions implement the complete emissions spatial processing workflow from the 2019 NEI emissions notebook.\n\nNotebook Step Function Notes\nRead FF10 files read_ff10 ✓ Complete\nConcatenate and aggregate aggregate_emissions ✓ Complete\nFilter pollutants filter_known_pollutants ✓ Complete\nMap pollutant names map_pollutant_names! ✓ Complete\nAssign surrogates via grid ref assign_surrogates ✓ Complete\nBuild shapefile map build_data_weight_map ✓ Complete\nCompute grid indices compute_grid_indices ✓ Complete\nGenerate sparse matrices generate_data_sparse_matrices, generate_weight_sparse_matrices, generate_grid_sparse_matrices ✓ Complete (uses GridDef instead of explicit bounds)\nCompute county surrogates generate_countySurrogate ✓ Complete\nRefine with surrogates refine_indices_with_surrogates ✓ Complete\nAllocate to grid allocate_emissions_to_grid ✓ Complete\nComplete workflow process_emissions_spatial ✓ Complete\nWrite output writeEmis ⚠ Simplified API, outputs DataFrame instead of shapefile\n\nNotes on Implementation Differences:\n\nSparse matrix functions: The implementation uses GridDef objects instead of explicit bounds/resolution parameters for better type safety and consistency with the rest of the package.\nWeight matrix generation: The implementation accepts pre-processed weight columns and factors instead of dynamic filter functions, providing a more predictable API.\nOutput format: The writeEmis function outputs structured DataFrames suitable for further processing, rather than directly writing shapefiles.\n\nThese differences make the implementation more composable and testable while maintaining full compatibility with the workflow described in the reference notebook. The core spatial processing workflow is complete and functional.","category":"section"},{"location":"spatial_processing/#Emissions.read_ff10","page":"Spatial Processing Pipeline","title":"Emissions.read_ff10","text":"read_ff10(filepath::AbstractString, format::Symbol) -> EmissionsDataFrame\n\nRead an FF10-format CSV file and return the appropriate EmissionsDataFrame subtype.\n\nformat must be one of :nonpoint, :point, :nonroad, or :onroad.\n\nExamples\n\nemis = read_ff10(\"nonpoint_2019.csv\", :nonpoint)\nemis.df  # access the underlying DataFrame\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.normalize_country","page":"Spatial Processing Pipeline","title":"Emissions.normalize_country","text":"normalize_country(country::AbstractString) -> String\n\nNormalize country codes to standard three-letter format. Maps \"US\" -> \"USA\", \"0\" -> \"USA\", \"1\" -> \"Canada\", \"2\" -> \"Mexico\". Already-standard codes are passed through unchanged.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.read_gridref","page":"Spatial Processing Pipeline","title":"Emissions.read_gridref","text":"read_gridref(file_path::AbstractString) -> DataFrame\n\nRead a SMOKE-format semicolon-delimited grid reference file. Lines starting with # are skipped. Each data line has the format: FIPS;SCC;Surrogate!comment\n\nExtracts COUNTRY from 6-digit FIPS codes and normalizes via normalize_country. Returns a DataFrame with columns: [:COUNTRY, :FIPS, :SCC, :Surrogate].\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.aggregate_emissions","page":"Spatial Processing Pipeline","title":"Emissions.aggregate_emissions","text":"aggregate_emissions(dfs::Vector{DataFrame}) -> DataFrame\n\nConcatenate multiple emission DataFrames, adding LONGITUDE and LATITUDE columns (as missing) for area sources that lack them, then group by [:POLID, :COUNTRY, :FIPS, :SCC, :LONGITUDE, :LATITUDE] and sum ANN_VALUE.\n\nThe result is sorted by ANN_VALUE descending.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.filter_known_pollutants","page":"Spatial Processing Pipeline","title":"Emissions.filter_known_pollutants","text":"filter_known_pollutants(df::DataFrame) -> DataFrame\n\nKeep only rows where POLID is a key in the Pollutants dictionary. Returns a filtered copy.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.map_pollutant_names!","page":"Spatial Processing Pipeline","title":"Emissions.map_pollutant_names!","text":"map_pollutant_names!(df::DataFrame) -> DataFrame\n\nMap POLID values to standard pollutant group names using the Pollutants dictionary (in-place). For example, \"EXH__VOC\" becomes \"VOC\" and \"PM25-PRI\" becomes \"PM25\".\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.assign_surrogates","page":"Spatial Processing Pipeline","title":"Emissions.assign_surrogates","text":"assign_surrogates(emissions::DataFrame, gridref::DataFrame) -> DataFrame\n\nAssign spatial surrogates to emissions records by joining with grid reference data.\n\nPerforms a left join on [:COUNTRY, :FIPS, :SCC]. For rows that remain unmatched (no surrogate assigned), falls back to a state-level match by retrying the join with FIPS=\"00000\" in the grid reference, then restoring the original FIPS code.\n\nReturns a copy of emissions with a Surrogate column added.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.build_data_weight_map","page":"Spatial Processing Pipeline","title":"Emissions.build_data_weight_map","text":"build_data_weight_map(emissions::DataFrame, srgSpecs::Vector{SurrogateSpec}) -> Dict{Tuple{String,String}, Vector{String}}\n\nIdentify which surrogates are actually needed based on the emissions data, and build a mapping from (data_shapefile, weight_shapefile) pairs to lists of \"Region+Code\" strings.\n\nThis avoids loading shapefiles that aren't referenced by any emissions record.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.find_surrogate_by_code-Tuple{Vector{SurrogateSpec}, String, Int64}","page":"Spatial Processing Pipeline","title":"Emissions.find_surrogate_by_code","text":"find_surrogate_by_code(srgSpecs::Vector{SurrogateSpec}, region::String, code::Int)\n\nFind a surrogate specification by its region and code number. Backward-compatible method; prefer using the keyword argument version.\n\n\n\n\n\n","category":"method"},{"location":"spatial_processing/#Emissions.location_key","page":"Spatial Processing Pipeline","title":"Emissions.location_key","text":"location_key(fips::AbstractString, lon, lat) -> String\n\nCompute a unique location key for an emissions record.\n\nPoint sources with valid coordinates return \"FIPS_lon_lat\". Area sources (missing coordinates) return the FIPS code.\n\nThis key is used to look up pre-computed grid cell allocations in the location index dictionary returned by compute_grid_indices.\n\nExamples\n\njulia> location_key(\"36001\", -73.5, 40.5)\n\"36001_-73.500000_40.500000\"\n\njulia> location_key(\"36001\", missing, missing)\n\"36001\"\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.compute_grid_indices","page":"Spatial Processing Pipeline","title":"Emissions.compute_grid_indices","text":"compute_grid_indices(emissions::DataFrame, grid::GridDef;\n                     counties_shapefile::String=\"\") -> Dict{String, IndexInfo}\n\nCompute grid cell indices for all unique emission locations.\n\nFor each unique location in the emissions data:\n\nPoint sources (rows with non-missing LONGITUDE and LATITUDE): finds the grid cell containing the point using GetIndex.\nArea sources (without coordinates): uses county polygon intersection with the grid if counties_shapefile is provided. The county polygon is looked up by FIPS code using findCountyPolygon.\n\nReturns a Dict{String, IndexInfo} mapping location keys (see location_key) to their grid cell allocations.\n\nArguments\n\nemissions::DataFrame: Must have a :FIPS column. May have :LONGITUDE and :LATITUDE.\ngrid::GridDef: Target grid definition.\ncounties_shapefile::String=\"\": Path to counties shapefile for area source indexing.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.refine_indices_with_surrogates","page":"Spatial Processing Pipeline","title":"Emissions.refine_indices_with_surrogates","text":"refine_indices_with_surrogates(locIndex::Dict{String, IndexInfo},\n    county_surrogates::Dict{String, SparseMatrixCSC{Float64, Int}}) -> Dict{String, IndexInfo}\n\nRefine area-source location indices using pre-computed county surrogate matrices.\n\nFor each FIPS-keyed entry in locIndex that has a matching entry in county_surrogates, replaces the area-based grid allocation with surrogate-weighted fractions via update_locIndex.\n\nPoint source entries (keys containing coordinates) are left unchanged, since point sources are allocated to their containing grid cell directly.\n\nArguments\n\nlocIndex: Location index dictionary from compute_grid_indices.\ncounty_surrogates: Pre-computed surrogate matrices from generate_countySurrogate, mapping FIPS codes to normalized allocation matrices.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.allocate_emissions_to_grid","page":"Spatial Processing Pipeline","title":"Emissions.allocate_emissions_to_grid","text":"allocate_emissions_to_grid(emissions::DataFrame,\n    locIndex::Dict{String, IndexInfo}, grid::GridDef;\n    pollutant_groups::Vector{String}=[\"VOC\", \"NOX\", \"NH3\", \"SO2\", \"PM25\"]) -> DataFrame\n\nDistribute emissions records to grid cells using pre-computed location indices.\n\nFor each emissions record:\n\nLooks up the grid cell allocation from locIndex using location_key\nDistributes ANN_VALUE across grid cells according to fractional coverage\nAccumulates results by (cellIndex, SCC) combination\n\nArguments\n\nemissions::DataFrame: Must have columns :FIPS, :SCC, :POLID, :ANN_VALUE. May have :LONGITUDE and :LATITUDE for point sources. ANN_VALUE may have Unitful units (they will be stripped).\nlocIndex: Location index from compute_grid_indices or refine_indices_with_surrogates.\ngrid::GridDef: Grid definition (used for cell index computation).\npollutant_groups: Pollutant names to include in output columns.\n\nReturns\n\nA DataFrame with columns: cellIndex, one column per pollutant group, and SCC. Each row represents accumulated emissions for a unique (cellIndex, SCC) combination, sorted by cellIndex.\n\n\n\n\n\n","category":"function"},{"location":"spatial_processing/#Emissions.process_emissions_spatial","page":"Spatial Processing Pipeline","title":"Emissions.process_emissions_spatial","text":"process_emissions_spatial(emissions::DataFrame, grid::GridDef;\n    counties_shapefile::String=\"\",\n    county_surrogates::Dict{String, SparseMatrixCSC{Float64, Int}}=Dict{String, SparseMatrixCSC{Float64, Int}}(),\n    pollutant_groups::Vector{String}=[\"VOC\", \"NOX\", \"NH3\", \"SO2\", \"PM25\"]) -> DataFrame\n\nExecute the complete spatial processing workflow on prepared emissions data.\n\nThis function orchestrates the full spatial allocation pipeline:\n\nCompute grid cell indices for all unique locations (compute_grid_indices)\nOptionally refine area-source indices with surrogate data (refine_indices_with_surrogates)\nAllocate emissions to grid cells (allocate_emissions_to_grid)\n\nThe input emissions DataFrame should already be processed through the data preparation pipeline (filter_known_pollutants, map_pollutant_names!).\n\nArguments\n\nemissions::DataFrame: Prepared emissions data with columns :FIPS, :SCC, :POLID, :ANN_VALUE. May have :LONGITUDE/:LATITUDE for point sources.\ngrid::GridDef: Target grid definition.\ncounties_shapefile::String=\"\": Path to counties shapefile for area source indexing.\ncounty_surrogates: Pre-computed surrogate matrices for index refinement.\npollutant_groups: Pollutant groups for output columns.\n\nReturns\n\nA DataFrame with gridded emissions, one row per (cellIndex, SCC) combination.\n\nExample\n\ngrid = NewGridIrregular(\"test\", 3, 3, \"EPSG:4326\", 1.0, 1.0, 0.0, 0.0)\nemissions = DataFrame(\n    FIPS=[\"00001\", \"00001\"], POLID=[\"NOX\", \"VOC\"],\n    SCC=[\"2103007000\", \"2103007000\"],\n    ANN_VALUE=[1.0e-3, 5.0e-4],\n    LONGITUDE=[0.5, 0.5], LATITUDE=[0.5, 0.5])\nresult = process_emissions_spatial(emissions, grid)\n\n\n\n\n\n","category":"function"},{"location":"orl/#ORL-Format","page":"ORL Format","title":"ORL Format","text":"","category":"section"},{"location":"orl/#Overview","page":"ORL Format","title":"Overview","text":"The ORL (One Record per Line) format is a legacy EPA inventory format used by SMOKE prior to the FF10 format. This module provides readers for all ORL inventory types, following the same pattern as the FF10 readers.\n\nSupported ORL formats:\n\nNonpoint (ARINV): Area source emissions\nPoint (PTINV): Point source emissions with stack parameters\nNonroad (ARINV): Mobile nonroad source emissions\nOnroad (MBINV): Mobile on-road source emissions\nFire (PTFIRE): Wildfire and prescribed fire emissions","category":"section"},{"location":"orl/#Usage","page":"ORL Format","title":"Usage","text":"","category":"section"},{"location":"orl/#Reading-ORL-Files","page":"ORL Format","title":"Reading ORL Files","text":"using Emissions\n\n# Read different ORL format types\n# emis = read_orl(\"nonpoint_inventory.csv\", :nonpoint)\n# emis = read_orl(\"point_inventory.csv\", :point)\n# emis = read_orl(\"fire_inventory.csv\", :fire)","category":"section"},{"location":"orl/#Unit-Conversions","page":"ORL Format","title":"Unit Conversions","text":"All ORL readers automatically perform the following conversions:\n\nEmission values: tons/year to kg/s (using tonperyear conversion factor)\nFIPS codes: Standardized to 5-digit format\nSCC codes: Left-padded to 10 digits\n\nFor point sources, stack parameters are additionally converted:\n\nStack height: feet to meters\nStack diameter: feet to meters\nStack temperature: Fahrenheit to Kelvin\nStack flow: ft³/s to m³/s\nStack velocity: ft/s to m/s","category":"section"},{"location":"orl/#Pipeline-Integration","page":"ORL Format","title":"Pipeline Integration","text":"ORL files can be used in the processing pipeline by setting inventory_type=:orl:\n\nresult = process_emissions(;\n    inventory_files = [(\"orl_inventory.csv\", :nonpoint)],\n    grid = my_grid,\n    inventory_type = :orl,  # Use ORL format readers\n    # ... other options\n)","category":"section"},{"location":"orl/#Emissions.ORLNonPointDataFrame","page":"ORL Format","title":"Emissions.ORLNonPointDataFrame","text":"ORLNonPointDataFrame <: EmissionsDataFrame\n\nWrapper for legacy ORL nonpoint emissions data. Validates that the DataFrame has 21 columns, renames them to standard names, standardizes FIPS/SCC codes, and converts units from tons/year to kg/s.\n\n\n\n\n\n","category":"type"},{"location":"orl/#Emissions.ORLPointDataFrame","page":"ORL Format","title":"Emissions.ORLPointDataFrame","text":"ORLPointDataFrame <: EmissionsDataFrame\n\nWrapper for legacy ORL point source emissions data. Validates that the DataFrame has 38 columns, renames them to standard names, standardizes FIPS/SCC codes, converts emission units, and converts stack parameters from imperial to SI units (feet→m, °F→K).\n\n\n\n\n\n","category":"type"},{"location":"orl/#Emissions.ORLNonRoadDataFrame","page":"ORL Format","title":"Emissions.ORLNonRoadDataFrame","text":"ORLNonRoadDataFrame <: EmissionsDataFrame\n\nWrapper for legacy ORL nonroad emissions data. Uses the same format as ORL nonpoint.\n\n\n\n\n\n","category":"type"},{"location":"orl/#Emissions.ORLOnRoadDataFrame","page":"ORL Format","title":"Emissions.ORLOnRoadDataFrame","text":"ORLOnRoadDataFrame <: EmissionsDataFrame\n\nWrapper for legacy ORL on-road emissions data. Uses the same format as ORL nonpoint.\n\n\n\n\n\n","category":"type"},{"location":"orl/#Emissions.ORLFireDataFrame","page":"ORL Format","title":"Emissions.ORLFireDataFrame","text":"ORLFireDataFrame <: EmissionsDataFrame\n\nWrapper for legacy ORL fire emissions data (PTFIRE format). Validates that the DataFrame has 21 columns, renames them to standard names, standardizes FIPS/SCC codes, and converts emission units.\n\nIncludes fire-specific fields: LATITUDE, LONGITUDE, HEATCONTENT, DATESTART, DATEEND.\n\n\n\n\n\n","category":"type"},{"location":"orl/#Emissions.read_orl","page":"ORL Format","title":"Emissions.read_orl","text":"read_orl(filepath::AbstractString, format::Symbol) -> EmissionsDataFrame\n\nRead an ORL-format CSV file and return the appropriate EmissionsDataFrame subtype.\n\nformat must be one of :nonpoint, :point, :nonroad, :onroad, or :fire.\n\nExamples\n\nemis = read_orl(\"nonpoint_2019.csv\", :nonpoint)\nemis.df  # access the underlying DataFrame\n\n\n\n\n\n","category":"function"},{"location":"speciation/#Chemical-Speciation","page":"Chemical Speciation","title":"Chemical Speciation","text":"","category":"section"},{"location":"speciation/#Overview","page":"Chemical Speciation","title":"Overview","text":"Chemical speciation converts inventory-level pollutants (e.g., VOC, NOX) into model-ready chemical species (e.g., FORM, ALD2, NO, NO2) required by air quality models such as CMAQ and CAMx. This implements the SMOKE Spcmat functionality.\n\nSpeciation uses two input files:\n\nGSPRO: Speciation profile file containing split factors and mass fractions\nGSREF: Cross-reference file mapping sources to speciation profiles","category":"section"},{"location":"speciation/#Usage","page":"Chemical Speciation","title":"Usage","text":"","category":"section"},{"location":"speciation/#Reading-Speciation-Files","page":"Chemical Speciation","title":"Reading Speciation Files","text":"using Emissions\n\n# Read speciation profiles and cross-reference\ngspro = read_gspro(\"path/to/gspro.txt\")\ngsref = read_gsref(\"path/to/gsref.txt\")","category":"section"},{"location":"speciation/#Applying-Speciation","page":"Chemical Speciation","title":"Applying Speciation","text":"# Apply mass-based speciation to emissions\nspeciated = speciate_emissions(emissions, gspro, gsref; basis=:mass)\n\n# Or mole-based speciation\nspeciated_mole = speciate_emissions(emissions, gspro, gsref; basis=:mole)","category":"section"},{"location":"speciation/#Pipeline-Integration","page":"Chemical Speciation","title":"Pipeline Integration","text":"Speciation integrates into the emissions processing pipeline after pollutant name mapping and before spatial allocation:\n\nresult = process_emissions(\n    inventory_files = [(\"inventory.csv\", :nonpoint)],\n    grid = grid,\n    gspro = gspro,\n    gsref = gsref,\n    speciation_basis = :mass,\n    # ... other arguments\n)","category":"section"},{"location":"speciation/#File-Formats","page":"Chemical Speciation","title":"File Formats","text":"","category":"section"},{"location":"speciation/#GSPRO-Format","page":"Chemical Speciation","title":"GSPRO Format","text":"Semicolon-delimited with 6 fields per line:\n\nprofile_code;pollutant_id;species_id;split_factor;divisor;mass_fraction","category":"section"},{"location":"speciation/#GSREF-Format","page":"Chemical Speciation","title":"GSREF Format","text":"Semicolon-delimited with 4 fields per line:\n\nFIPS;SCC;pollutant_id;profile_code","category":"section"},{"location":"speciation/#Hierarchical-Matching","page":"Chemical Speciation","title":"Hierarchical Matching","text":"GSREF matching follows a 3-level hierarchy:\n\nExact FIPS + SCC + pollutant match\nNational default (FIPS=\"00000\") + SCC + pollutant\nPollutant-only match (SCC=\"0000000000\")","category":"section"},{"location":"speciation/#Emissions.read_gspro","page":"Chemical Speciation","title":"Emissions.read_gspro","text":"read_gspro(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format GSPRO speciation profile file.\n\nLines starting with # are skipped. Each data line has semicolon-delimited fields: profile_code;pollutant_id;species_id;split_factor;divisor;mass_fraction\n\nReturns\n\nA DataFrame with columns:\n\n:profile_code (String): Speciation profile identifier\n:pollutant_id (String): Inventory pollutant name (e.g., \"VOC\", \"NOX\")\n:species_id (String): Model species name (e.g., \"NO\", \"NO2\", \"FORM\")\n:split_factor (Float64): Mole-based split factor (numerator)\n:divisor (Float64): Mole-based divisor (denominator)\n:mass_fraction (Float64): Mass-based speciation fraction\n\n\n\n\n\n","category":"function"},{"location":"speciation/#Emissions.read_gsref","page":"Chemical Speciation","title":"Emissions.read_gsref","text":"read_gsref(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format GSREF speciation cross-reference file.\n\nMaps emission sources (by FIPS and SCC) to speciation profiles for each pollutant. Lines starting with # are skipped. Each data line has semicolon-delimited fields: FIPS;SCC;pollutant_id;profile_code\n\nFIPS codes are normalized: 6-digit codes have the country digit stripped and are left-padded to 5 digits. \"00000\" serves as the national default.\n\nReturns\n\nA DataFrame with columns:\n\n:FIPS (String): 5-digit FIPS code (\"00000\" for national default)\n:SCC (String): Source Classification Code\n:pollutant_id (String): Inventory pollutant name\n:profile_code (String): Speciation profile code (matches GSPRO)\n\n\n\n\n\n","category":"function"},{"location":"speciation/#Emissions.build_speciation_matrix","page":"Chemical Speciation","title":"Emissions.build_speciation_matrix","text":"build_speciation_matrix(emissions::DataFrame, gspro::DataFrame, gsref::DataFrame;\n    basis::Symbol=:mass) -> (Matrix{Float64}, Vector{String}, Vector{Int})\n\nBuild a speciation matrix mapping inventory sources to model species.\n\nArguments\n\nemissions::DataFrame: Must have columns :FIPS, :SCC, :POLID.\ngspro::DataFrame: Speciation profiles from read_gspro.\ngsref::DataFrame: Cross-reference from read_gsref.\nbasis::Symbol=:mass: :mass uses mass_fraction, :mole uses split_factor/divisor.\n\nReturns\n\nA tuple of:\n\nmatrix::Matrix{Float64}: (nsources × nspecies) speciation factors\nspecies_names::Vector{String}: Species names for each column\nsource_indices::Vector{Int}: Row index in emissions for each matrix row\n\n\n\n\n\n","category":"function"},{"location":"speciation/#Emissions.speciate_emissions","page":"Chemical Speciation","title":"Emissions.speciate_emissions","text":"speciate_emissions(emissions::DataFrame, gspro::DataFrame, gsref::DataFrame;\n    basis::Symbol=:mass) -> DataFrame\n\nApply chemical speciation to convert inventory pollutants into model species.\n\nFor each emissions record, looks up the speciation profile via GSREF and applies the speciation factors from GSPRO. The output has :POLID replaced with model species names, with ANN_VALUE split according to speciation factors.\n\nArguments\n\nemissions::DataFrame: Must have columns :FIPS, :SCC, :POLID, :ANN_VALUE. May also have :COUNTRY, :LONGITUDE, :LATITUDE, :Surrogate.\ngspro::DataFrame: Speciation profiles from read_gspro.\ngsref::DataFrame: Cross-reference from read_gsref.\nbasis::Symbol=:mass: :mass uses mass_fraction, :mole uses split_factor/divisor.\n\nReturns\n\nA DataFrame with the same columns as input, with :POLID values replaced by model species names and :ANN_VALUE scaled by the speciation factor. Each input row may produce multiple output rows (one per model species).\n\nRecords with no matching speciation profile are passed through with :POLID set to the original pollutant name and :ANN_VALUE unchanged.\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Temporal-Processing","page":"Temporal Processing","title":"Temporal Processing","text":"","category":"section"},{"location":"temporal_processing/#Overview","page":"Temporal Processing","title":"Overview","text":"The temporal allocation module converts annual emissions inventory data to hourly emissions using temporal profiles. This implements the SMOKE Temporal program functionality.\n\nTemporal allocation uses three types of profiles:\n\nMonthly profiles: 12 factors distributing annual total across months (sum to 1.0)\nWeekly profiles: 7 factors for day-of-week weighting (sum to 7.0)\nDiurnal profiles: 24 factors distributing daily total across hours (sum to 1.0)","category":"section"},{"location":"temporal_processing/#API-Reference","page":"Temporal Processing","title":"API Reference","text":"","category":"section"},{"location":"temporal_processing/#Profile-I/O","page":"Temporal Processing","title":"Profile I/O","text":"","category":"section"},{"location":"temporal_processing/#Temporal-Allocation","page":"Temporal Processing","title":"Temporal Allocation","text":"","category":"section"},{"location":"temporal_processing/#Merging","page":"Temporal Processing","title":"Merging","text":"After temporal and spatial allocation, emissions from different source categories are merged into final gridded hourly output.","category":"section"},{"location":"temporal_processing/#Example","page":"Temporal Processing","title":"Example","text":"using Emissions\nusing DataFrames\nusing Dates\n\n# Create synthetic annual emissions\nemissions = DataFrame(\n    FIPS = [\"36001\", \"36005\"],\n    SCC = [\"2103007000\", \"2103007000\"],\n    POLID = [\"NOX\", \"VOC\"],\n    ANN_VALUE = [100.0, 50.0]\n)\n\n# Create uniform temporal profiles\nprofiles = DataFrame(\n    profile_type = [\"MONTHLY\", \"WEEKLY\", \"DIURNAL\"],\n    profile_id = [1, 1, 1],\n    factors = [fill(1.0/12.0, 12), fill(1.0, 7), fill(1.0/24.0, 24)]\n)\n\n# Create cross-reference mapping all SCCs to profile ID 1\nxref = DataFrame(\n    FIPS = [\"00000\"],\n    SCC = [\"2103007000\"],\n    monthly_id = [1],\n    weekly_id = [1],\n    diurnal_id = [1]\n)\n\n# Allocate for a 24-hour episode\nep_start = DateTime(2019, 7, 1, 0)\nep_end = DateTime(2019, 7, 2, 0)\n\nhourly = temporal_allocate(emissions, profiles, xref, ep_start, ep_end)\nprintln(\"Hourly records: \", nrow(hourly))\nfirst(hourly, 5)\n\n# Merge with spatial allocation\nusing SparseArrays\n\ngrid = NewGridIrregular(\"test\", 2, 2, \"EPSG:4326\", 1.0, 1.0, 0.0, 0.0)\nlocIndex = Dict{String, IndexInfo}(\n    \"36001\" => IndexInfo([1, 1], [1, 2], [0.6, 0.4], true, true),\n    \"36005\" => IndexInfo([2], [1], [1.0], true, true)\n)\n\ngridded = merge_emissions(hourly, locIndex, grid)\nprintln(\"Gridded records: \", nrow(gridded))\nfirst(gridded, 5)","category":"section"},{"location":"temporal_processing/#Emissions.read_temporal_profiles","page":"Temporal Processing","title":"Emissions.read_temporal_profiles","text":"read_temporal_profiles(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format temporal profile file (ATPRO/MTPRO).\n\nThe file contains monthly, weekly, and diurnal profile factors. Lines starting with # or /PROFILE/ are skipped. Each data line has the format: profile_type, profile_id, factor1, factor2, ...\n\nProfile types:\n\nMONTHLY: 12 factors (Jan-Dec) that sum to 1.0\nWEEKLY: 7 factors (Mon-Sun) that sum to 7.0\nDIURNAL or ALLDAY: 24 factors (hours 0-23) that sum to 1.0\nDay-specific: MONDAY, TUESDAY, ..., SUNDAY, WEEKDAY, WEEKEND\n\nReturns a DataFrame with columns: [:profile_type, :profile_id, :factors] where factors is a Vector{Float64}.\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.read_temporal_xref","page":"Temporal Processing","title":"Emissions.read_temporal_xref","text":"read_temporal_xref(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format temporal cross-reference file (ATREF/MTREF).\n\nMaps SCC codes to temporal profile IDs. Lines starting with # are skipped. Each data line has the format: FIPS;SCC;monthly_profile_id;weekly_profile_id;diurnal_profile_id[!comment]\n\nReturns a DataFrame with columns: [:FIPS, :SCC, :monthly_id, :weekly_id, :diurnal_id]\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.read_day_specific","page":"Temporal Processing","title":"Emissions.read_day_specific","text":"read_day_specific(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format day-specific emissions file (PTDAY/ARDAY).\n\nEach data line has the format: FIPS;SCC;POLID;date;day_emis[!comment]\n\nReturns a DataFrame with columns: [:FIPS, :SCC, :POLID, :date (Date), :day_value (Float64)]\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.read_hour_specific","page":"Temporal Processing","title":"Emissions.read_hour_specific","text":"read_hour_specific(filepath::AbstractString) -> DataFrame\n\nRead a SMOKE-format hour-specific emissions file (PTHOURLY/ARHOURLY).\n\nEach data line has the format: FIPS;SCC;POLID;date;h0;h1;...;h23[!comment]\n\nReturns a DataFrame with columns: [:FIPS, :SCC, :POLID, :date (Date), :hourly_values (Vector{Float64})]\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.temporal_allocate","page":"Temporal Processing","title":"Emissions.temporal_allocate","text":"temporal_allocate(emissions::DataFrame, profiles::DataFrame,\n    xref::DataFrame, episode_start::DateTime, episode_end::DateTime;\n    timezone_offset::Int=0,\n    timezone_map::Dict{String,Int}=Dict{String,Int}(),\n    day_specific::DataFrame=DataFrame(),\n    hour_specific::DataFrame=DataFrame()) -> DataFrame\n\nConvert annual emissions to hourly emissions using temporal profiles.\n\nApplies monthly, day-of-week, and diurnal temporal factors to distribute annual emissions to hourly values for the specified episode period.\n\nSupports SMOKE-style priority hierarchy for temporal overrides:\n\nHour-specific data → use directly (bypass all profiles)\nDay-specific data → use with diurnal profile (bypass monthly/weekly)\nAnnual with profiles → standard monthly × weekly × diurnal allocation\n\nArguments\n\nemissions::DataFrame: Annual emissions with columns :FIPS, :SCC, :POLID, :ANN_VALUE. ANN_VALUE should be in mass/time units (e.g., kg/s). May also have :LONGITUDE, :LATITUDE, :COUNTRY, and :Surrogate.\nprofiles::DataFrame: Temporal profiles from read_temporal_profiles.\nxref::DataFrame: Temporal cross-reference from read_temporal_xref.\nepisode_start::DateTime: Start of the episode period.\nepisode_end::DateTime: End of the episode period.\ntimezone_offset::Int=0: Default UTC offset in hours for local time adjustment.\ntimezone_map::Dict{String,Int}=Dict{String,Int}(): Optional per-FIPS timezone offsets (FIPS code => UTC offset). When present, overrides timezone_offset for sources with matching FIPS codes.\nday_specific::DataFrame=DataFrame(): Day-specific emissions from read_day_specific. When matched, overrides monthly/weekly profile allocation.\nhour_specific::DataFrame=DataFrame(): Hour-specific emissions from read_hour_specific. When matched, overrides all profile-based allocation.\n\nReturns\n\nA DataFrame with columns: :FIPS, :SCC, :POLID, :hour (DateTime), :emission_rate (Float64), plus any location columns from the input.\n\nThe temporal allocation follows SMOKE conventions:\n\nMonthly factor: fraction of annual total for the given month (sums to 1.0)\nWeekly factor: relative weight for the day of week (sums to 7.0)\nDiurnal factor: fraction of daily total for the given hour (sums to 1.0)\nHourly rate = ANNVALUE × monthlyfactor × (weeklyfactor / 7) × (diurnalfactor × 24)\nDiurnal profiles are selected with SMOKE-style day-specific fallback: DIURNAL → day name (MONDAY, etc.) → WEEKDAY/WEEKEND → ALLDAY → uniform\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.merge_emissions","page":"Temporal Processing","title":"Emissions.merge_emissions","text":"merge_emissions(hourly_emissions::DataFrame, locIndex::Dict{String, IndexInfo},\n    grid::GridDef; pollutant_groups::Vector{String}=[\"VOC\", \"NOX\", \"NH3\", \"SO2\", \"PM25\"]) -> DataFrame\n\nCombine temporally-allocated hourly emissions with spatial allocation to produce gridded hourly emissions.\n\nFor each hour and source:\n\nLooks up the spatial allocation (grid cells and fractions) from locIndex\nDistributes the hourly emission rate across grid cells according to fractions\nAccumulates results by (grid_row, grid_col, hour, pollutant) combination\n\nArguments\n\nhourly_emissions::DataFrame: From temporal_allocate, with columns :FIPS, :SCC, :POLID, :hour, :emission_rate. May also have :LONGITUDE and :LATITUDE for point sources.\nlocIndex: Pre-computed location index from compute_grid_indices.\ngrid::GridDef: Target grid definition.\npollutant_groups: Pollutant groups to include in output.\n\nReturns\n\nA DataFrame with columns: :grid_row, :grid_col, :hour, :pollutant, :emission_rate. Each row represents accumulated emissions for a unique grid cell, hour, and pollutant.\n\n\n\n\n\n","category":"function"},{"location":"temporal_processing/#Emissions.merge_categories","page":"Temporal Processing","title":"Emissions.merge_categories","text":"merge_categories(dfs::DataFrame...) -> DataFrame\nmerge_categories(dfs::Vector{DataFrame}) -> DataFrame\n\nCombine gridded emissions from different source categories (area, point, mobile, etc.).\n\nStacks DataFrames and sums emissions for the same (grid_row, grid_col, hour, pollutant).\n\nArguments\n\ndfs: One or more DataFrames with columns :grid_row, :grid_col, :hour, :pollutant, :emission_rate.\n\nReturns\n\nA combined DataFrame with summed emission rates, sorted by hour, row, col, pollutant.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#NEI-Processing","page":"NEI Processing","title":"NEI Processing","text":"","category":"section"},{"location":"nei_processing/#Overview","page":"NEI Processing","title":"Overview","text":"The Emissions.jl package provides tools for processing EPA National Emissions Inventory (NEI) data. It supports reading FF10-format emissions files, spatial allocation using surrogate shapefiles, and gridding emissions to model-ready formats.\n\nThe package also includes plume rise calculations based on ASME (1973), as described in Seinfeld and Pandis, \"Atmospheric Chemistry and Physics - From Air Pollution to Climate Change\".","category":"section"},{"location":"nei_processing/#Plume-Rise","page":"NEI Processing","title":"Plume Rise","text":"The following functions implement the ASME (1973) plume rise algorithm:\n\nfindLayer - Find the model layer containing a given height\ncalcDeltaH - Calculate plume rise\nASME - Calculate effective emissions height with plume rise\ncalcDeltaHPrecomputed - Calculate plume rise with precomputed meteorological parameters\nASMEPrecomputed - Calculate effective emissions height with precomputed parameters","category":"section"},{"location":"nei_processing/#Constants-and-Unit-Conversions","page":"NEI Processing","title":"Constants and Unit Conversions","text":"","category":"section"},{"location":"nei_processing/#Data-Types","page":"NEI Processing","title":"Data Types","text":"","category":"section"},{"location":"nei_processing/#FF10-Data-Formats","page":"NEI Processing","title":"FF10 Data Formats","text":"The EPA FF10 (Flat File 10) format is the standard format for emissions inventory data. The package supports four FF10 format types:","category":"section"},{"location":"nei_processing/#I/O-Functions","page":"NEI Processing","title":"I/O Functions","text":"","category":"section"},{"location":"nei_processing/#Spatial-Processing","page":"NEI Processing","title":"Spatial Processing","text":"","category":"section"},{"location":"nei_processing/#Surrogate-Operations","page":"NEI Processing","title":"Surrogate Operations","text":"","category":"section"},{"location":"nei_processing/#Output","page":"NEI Processing","title":"Output","text":"","category":"section"},{"location":"nei_processing/#Pipeline-Functions","page":"NEI Processing","title":"Pipeline Functions","text":"See the Spatial Processing Pipeline page for documentation on the mid-level pipeline functions: read_ff10, normalize_country, read_gridref, aggregate_emissions, filter_known_pollutants, map_pollutant_names!, assign_surrogates, and build_data_weight_map.","category":"section"},{"location":"nei_processing/#Emissions.tonperyear","page":"NEI Processing","title":"Emissions.tonperyear","text":"tonperyear\n\nConversion factor from tons per year to kg per second. 1 ton = 907.185 kg, 1 year = 31,536,000 seconds.\n\n\n\n\n\n","category":"constant"},{"location":"nei_processing/#Emissions.tonpermonth","page":"NEI Processing","title":"Emissions.tonpermonth","text":"tonpermonth\n\nConversion factor from tons per month to kg per second. 1 ton = 907.185 kg, 1 month = 2,628,288 seconds (average month).\n\n\n\n\n\n","category":"constant"},{"location":"nei_processing/#Emissions.foot","page":"NEI Processing","title":"Emissions.foot","text":"foot\n\nConversion factor from feet to meters. 1 foot = 0.3048 meters.\n\n\n\n\n\n","category":"constant"},{"location":"nei_processing/#Emissions.kelvin","page":"NEI Processing","title":"Emissions.kelvin","text":"kelvin(F)\n\nConvert temperature from Fahrenheit to Kelvin.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.Pollutants","page":"NEI Processing","title":"Emissions.Pollutants","text":"Pollutants\n\nDictionary mapping specific pollutant identifiers to aggregated pollutant group names.\n\n\n\n\n\n","category":"constant"},{"location":"nei_processing/#Emissions.EmissionsDataFrame","page":"NEI Processing","title":"Emissions.EmissionsDataFrame","text":"EmissionsDataFrame\n\nAbstract type for emissions data frames wrapping FF10 format data.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.SurrogateSpec","page":"NEI Processing","title":"Emissions.SurrogateSpec","text":"SurrogateSpec\n\nHolds surrogate specification data for spatial allocation of emissions.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.GridDef","page":"NEI Processing","title":"Emissions.GridDef","text":"GridDef\n\nSpecifies the grid that we are allocating the emissions to. Each cell is described by its bounding box in Extent: [(xmin, ymin), (xmax, ymax)].\n\nFor regular grids (uniform dx, dy), optional fields Dx, Dy, X0, Y0 enable O(1) point-in-cell lookup instead of linear scan.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.SpatialProcessor","page":"NEI Processing","title":"Emissions.SpatialProcessor","text":"SpatialProcessor\n\nSpatializes emissions records using surrogate specifications and grid definitions.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.Config","page":"NEI Processing","title":"Emissions.Config","text":"Config\n\nHolds configuration data for the emissions processing pipeline.\n\nFields\n\nf_gridRef: Paths to grid reference files\nSrgSpec: Path to surrogate specification file\nSrgShapefileDirectory: Directory containing surrogate shapefiles\nInputSR: Input spatial reference (projection string)\nOutputSR: Output spatial reference (projection string)\nGridFile: Path to grid definition file\nGridName: Name of the grid\nCounties: Path to counties shapefile\nEmisShp: Path to output emissions shapefile directory\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.IndexInfo","page":"NEI Processing","title":"Emissions.IndexInfo","text":"IndexInfo\n\nHolds grid index information for gridded emissions, including which grid cells a source maps to and the fraction of emissions allocated to each cell.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.FF10NonPointDataFrame","page":"NEI Processing","title":"Emissions.FF10NonPointDataFrame","text":"FF10NonPointDataFrame <: EmissionsDataFrame\n\nWrapper for EPA FF10 nonpoint emissions data. Validates that the DataFrame has 45 columns, renames them to standard names, standardizes FIPS/SCC codes, and converts units.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.FF10PointDataFrame","page":"NEI Processing","title":"Emissions.FF10PointDataFrame","text":"FF10PointDataFrame <: EmissionsDataFrame\n\nWrapper for EPA FF10 point source emissions data. Validates that the DataFrame has 77 columns, renames them to standard names, standardizes FIPS/SCC codes, converts units, and converts stack parameters from imperial to SI units.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.FF10NonRoadDataFrame","page":"NEI Processing","title":"Emissions.FF10NonRoadDataFrame","text":"FF10NonRoadDataFrame <: EmissionsDataFrame\n\nWrapper for EPA FF10 nonroad emissions data. Uses the same format as nonpoint.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.FF10OnRoadDataFrame","page":"NEI Processing","title":"Emissions.FF10OnRoadDataFrame","text":"FF10OnRoadDataFrame <: EmissionsDataFrame\n\nWrapper for EPA FF10 on-road emissions data. Uses the same format as nonpoint.\n\n\n\n\n\n","category":"type"},{"location":"nei_processing/#Emissions.strip_missing","page":"NEI Processing","title":"Emissions.strip_missing","text":"strip_missing(df::DataFrame)\n\nReplace all missing values in a DataFrame with empty strings.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.getCountry","page":"NEI Processing","title":"Emissions.getCountry","text":"getCountry(fips::AbstractString)\n\nReturn the country name based on the first digit of the FIPS code.\n\n'0' or '9' => \"US\"\n'1' => \"Mexico\"\n'2' => \"Canada\"\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.read_grid","page":"NEI Processing","title":"Emissions.read_grid","text":"read_grid(file::AbstractString)\n\nRead a grid definition file (IOAPI-style GRIDDESC format) and return a DataFrame with columns FIPS, Longitude, and Latitude.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.getShapefilePath","page":"NEI Processing","title":"Emissions.getShapefilePath","text":"getShapefilePath(dir::AbstractString, name::AbstractString, check::Bool=true)\n\nFind the full path to a shapefile within the given directory tree. Searches recursively for files with .shp extension matching the given name.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.validateShapefile","page":"NEI Processing","title":"Emissions.validateShapefile","text":"validateShapefile(path::AbstractString)\n\nCheck that a shapefile path is non-empty and the file exists.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.readSrgSpecSMOKE","page":"NEI Processing","title":"Emissions.readSrgSpecSMOKE","text":"readSrgSpecSMOKE(file::AbstractString, SrgShapefileDirectory::AbstractString, CheckShapefiles::Bool=false)\n\nRead a SMOKE-format spatial surrogate specification file and return a vector of SurrogateSpec objects.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.NewSpatialProcessor","page":"NEI Processing","title":"Emissions.NewSpatialProcessor","text":"NewSpatialProcessor(srgSpecs, grids, gridRef, inputSR, matchFullSCC)\n\nCreate a new SpatialProcessor with default cache and merge depth settings.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.NewPolygon","page":"NEI Processing","title":"Emissions.NewPolygon","text":"NewPolygon(coords::Vector{Tuple{Float64,Float64}})\n\nCreate a GeoInterface polygon from a vector of coordinate tuples. The polygon is automatically closed if needed.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.NewGridIrregular","page":"NEI Processing","title":"Emissions.NewGridIrregular","text":"NewGridIrregular(name, nx, ny, sr, dx, dy, x0, y0)\n\nCreate a GridDef with a regular (but potentially projected) grid.\n\n\n\n\n\nNewGridIrregular(name, filepath, inputSR, outputSR)\n\nCreate an irregular grid by reading polygon coordinates from a file. The file should contain polygon coordinate strings in the format used by the NEI processing notebook.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.setupSpatialProcessor","page":"NEI Processing","title":"Emissions.setupSpatialProcessor","text":"setupSpatialProcessor(config::Config)\n\nSet up a SpatialProcessor from a configuration object. Reads grid reference files, surrogate specifications, and grid definitions.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.findCountyPolygon","page":"NEI Processing","title":"Emissions.findCountyPolygon","text":"findCountyPolygon(fips::AbstractString, countyShapefile::AbstractString)\n\nFind and return the polygon for a given FIPS code from a county shapefile. Uses GeoDataFrames to read the shapefile. Returns a GeoInterface-compatible geometry or nothing if not found.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.GetIndex","page":"NEI Processing","title":"Emissions.GetIndex","text":"GetIndex(lon, lat, grid::GridDef)\n\nFind which grid cell contains the point (lon, lat) and return an IndexInfo. Uses bounding box containment for efficient point-in-cell lookup.\n\n\n\n\n\nGetIndex(geom, grid::GridDef)\n\nFind which grid cells a geometry intersects, and return an IndexInfo with the row/column indices and fractional coverage. Uses GeometryOps.intersection to compute intersection polygons and areas for each grid cell.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.recordToGrid","page":"NEI Processing","title":"Emissions.recordToGrid","text":"recordToGrid(emissions::Float64, index::IndexInfo, grid_nx::Int, grid_ny::Int)\n\nDistribute emissions to grid cells according to the fractional coverage in IndexInfo. Returns a sparse matrix of emissions.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.GridFactors","page":"NEI Processing","title":"Emissions.GridFactors","text":"GridFactors(grid::GridDef)\n\nReturn a matrix of grid cell areas.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.uniqueCoordinates","page":"NEI Processing","title":"Emissions.uniqueCoordinates","text":"uniqueCoordinates(lons::Vector{Float64}, lats::Vector{Float64})\n\nReturn the indices of unique (lon, lat) coordinate pairs.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.uniqueLoc","page":"NEI Processing","title":"Emissions.uniqueLoc","text":"uniqueLoc(lons::Vector{Float64}, lats::Vector{Float64})\n\nReturn a dictionary mapping unique (lon, lat) pairs to their first occurrence index.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.generate_data_sparse_matrices","page":"NEI Processing","title":"Emissions.generate_data_sparse_matrices","text":"generate_data_sparse_matrices(shapefile_path, attribute, grid, inputSR)\n\nRead a data shapefile using GeoDataFrames and generate sparse matrices representing the spatial allocation of each region (identified by attribute) to grid cells. Returns a dictionary mapping attribute values to sparse matrices.\n\nUses ConservativeRegridding.jl for efficient area-overlap computation via spatial indexing.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.generate_weight_sparse_matrices","page":"NEI Processing","title":"Emissions.generate_weight_sparse_matrices","text":"generate_weight_sparse_matrices(shapefile_path, weight_columns, weight_factors, grid, inputSR)\n\nRead a weight shapefile using GeoDataFrames and generate sparse matrices of weighted values on the grid.\n\nUses ConservativeRegridding.jl for efficient area-overlap computation.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.generate_grid_sparse_matrices","page":"NEI Processing","title":"Emissions.generate_grid_sparse_matrices","text":"generate_grid_sparse_matrices(grid::GridDef)\n\nGenerate a sparse matrix of grid cell areas.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.generate_countySurrogate","page":"NEI Processing","title":"Emissions.generate_countySurrogate","text":"generate_countySurrogate(data_matrices, weight_matrix, grid_matrix)\n\nGenerate a surrogate matrix by combining data and weight matrices. For each region in data_matrices, the surrogate is computed as:   surrogate = (data .* weight) / sum(data .* weight) Falls back to area-based allocation if weight sum is zero.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.update_locIndex","page":"NEI Processing","title":"Emissions.update_locIndex","text":"update_locIndex(locIndex::Dict, fips::AbstractString, surrogates::Dict)\n\nUpdate a location index dictionary with surrogate allocation data for a given FIPS code. Returns the IndexInfo for the FIPS code from the surrogates, or a default empty IndexInfo.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.find_surrogate_by_code","page":"NEI Processing","title":"Emissions.find_surrogate_by_code","text":"find_surrogate_by_code(srgSpecs::Vector{SurrogateSpec}, code::Int; region::String=\"\") -> Union{SurrogateSpec, Nothing}\n\nFind a surrogate specification by its code number, with optional region filtering.\n\nWhen region is non-empty, only matches surrogates with that region. When region is empty (default), matches any region.\n\nReturns the matching SurrogateSpec or nothing if not found.\n\n\n\n\n\nfind_surrogate_by_code(srgSpecs::Vector{SurrogateSpec}, region::String, code::Int)\n\nFind a surrogate specification by its region and code number. Backward-compatible method; prefer using the keyword argument version.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.get_data_weight_shapefiles","page":"NEI Processing","title":"Emissions.get_data_weight_shapefiles","text":"get_data_weight_shapefiles(srg::SurrogateSpec)\n\nReturn a tuple of (datashapefile, weightshapefile) paths from a surrogate specification.\n\n\n\n\n\n","category":"function"},{"location":"nei_processing/#Emissions.writeEmis","page":"NEI Processing","title":"Emissions.writeEmis","text":"writeEmis(filename, grid_data, grid::GridDef; pollutant=\"\", units=\"\")\n\nWrite gridded emissions data to a CSV file.\n\nArguments\n\nfilename: Output file path\ngrid_data: Matrix or sparse matrix of emissions values\ngrid: Grid definition\npollutant: Pollutant name (optional, for header)\nunits: Units string (optional, for header)\n\n\n\n\n\n","category":"function"},{"location":"regridding/#Spatial-Allocation-with-ConservativeRegridding","page":"Conservative Regridding","title":"Spatial Allocation with ConservativeRegridding","text":"","category":"section"},{"location":"regridding/#Overview","page":"Conservative Regridding","title":"Overview","text":"Emissions.jl provides spatial allocation using ConservativeRegridding.jl for efficient, mathematically rigorous conservative regridding. This approach uses precomputed intersection area matrices with spatial indexing (STRtree) for better performance with large grids compared to manual polygon intersection loops.","category":"section"},{"location":"regridding/#Usage","page":"Conservative Regridding","title":"Usage","text":"","category":"section"},{"location":"regridding/#Building-a-Regridder","page":"Conservative Regridding","title":"Building a Regridder","text":"using Emissions\nimport GeoInterface as GI\n\n# Define grid\ngrid = NewGridIrregular(\"test\", 10, 10, \"EPSG:4326\", 0.5, 0.5, -80.0, 35.0)\n\n# Source geometries (e.g., county polygons)\nsource_geoms = [...]  # Vector of GeoInterface polygons\n\n# Build reusable regridder\nregridder = build_regridder(source_geoms, grid)","category":"section"},{"location":"regridding/#Surrogate-Generation","page":"Conservative Regridding","title":"Surrogate Generation","text":"The _cr variants of the surrogate generation functions use ConservativeRegridding internally for computing intersection areas:\n\n# Using ConservativeRegridding (recommended for large grids)\ndata_matrices = generate_data_sparse_matrices_cr(\n    \"counties.shp\", \"FIPS\", grid, \"EPSG:4326\"\n)\nweight_matrix = generate_weight_sparse_matrices_cr(\n    \"population.shp\", [\"POP\"], [1.0], grid, \"EPSG:4326\"\n)\n\n# Original GeometryOps-based approach (compatible fallback)\ndata_matrices_orig = generate_data_sparse_matrices(\n    \"counties.shp\", \"FIPS\", grid, \"EPSG:4326\"\n)","category":"section"},{"location":"regridding/#Performance","page":"Conservative Regridding","title":"Performance","text":"ConservativeRegridding.jl uses Sort-Tile-Recursive (STR) tree spatial indexing to efficiently identify intersecting polygon pairs, avoiding the O(n*m) brute force approach of checking every source geometry against every grid cell. This provides significant speedups for large grids and many source polygons.","category":"section"},{"location":"regridding/#Emissions.build_regridder","page":"Conservative Regridding","title":"Emissions.build_regridder","text":"build_regridder(source_geometries::Vector, grid::GridDef) -> ConservativeRegridding.Regridder\n\nBuild a ConservativeRegridding.jl Regridder from source geometries to grid cells.\n\nThe regridder computes intersection areas between all source geometries and grid cells using an efficient spatial index (STRtree). The resulting object can be reused for multiple regridding operations on the same grid.\n\nArguments\n\nsource_geometries: Vector of GeoInterface-compatible polygon geometries.\ngrid::GridDef: Target grid definition.\n\nReturns\n\nA ConservativeRegridding.Regridder that can be used with ConservativeRegridding.regrid.\n\n\n\n\n\n","category":"function"},{"location":"regridding/#Emissions.grid_polygons","page":"Conservative Regridding","title":"Emissions.grid_polygons","text":"grid_polygons(grid::GridDef) -> Vector\n\nReturn a vector of GeoInterface polygons for all grid cells, ordered by cell index (j-1)*Nx + i.\n\n\n\n\n\n","category":"function"},{"location":"regridding/#Emissions.generate_data_sparse_matrices_cr","page":"Conservative Regridding","title":"Emissions.generate_data_sparse_matrices_cr","text":"generate_data_sparse_matrices_cr(shapefile_path, attribute, grid, inputSR)\n\nAlias for generate_data_sparse_matrices. The standard implementation now uses ConservativeRegridding.jl by default.\n\n\n\n\n\n","category":"function"},{"location":"regridding/#Emissions.generate_weight_sparse_matrices_cr","page":"Conservative Regridding","title":"Emissions.generate_weight_sparse_matrices_cr","text":"generate_weight_sparse_matrices_cr(shapefile_path, weight_columns, weight_factors, grid, inputSR)\n\nAlias for generate_weight_sparse_matrices. The standard implementation now uses ConservativeRegridding.jl by default.\n\n\n\n\n\n","category":"function"},{"location":"elevpoint/#Elevated-Source-Identification","page":"Elevated Source Identification","title":"Elevated Source Identification","text":"","category":"section"},{"location":"elevpoint/#Overview","page":"Elevated Source Identification","title":"Overview","text":"Elevated source identification implements the SMOKE Elevpoint functionality. It classifies point sources as surface-level, elevated, or Plume-in-Grid (PinG) based on stack parameters and analytical plume rise estimates. This classification determines how sources are treated in vertical layer allocation and air quality modeling.","category":"section"},{"location":"elevpoint/#Usage","page":"Elevated Source Identification","title":"Usage","text":"","category":"section"},{"location":"elevpoint/#Classifying-Point-Sources","page":"Elevated Source Identification","title":"Classifying Point Sources","text":"using Emissions\n\n# Classify with default SMOKE criteria\nclassified = classify_point_sources(point_emissions)\n\n# Filter by class\nelevated = filter(r -> r.source_class == \"elevated\", classified)\nping = filter(r -> r.source_class == \"ping\", classified)\nsurface = filter(r -> r.source_class == \"surface\", classified)","category":"section"},{"location":"elevpoint/#Custom-Criteria","page":"Elevated Source Identification","title":"Custom Criteria","text":"criteria = ElevationCriteria(\n    20.0,   # min stack height (m)\n    5.0,    # min exit velocity (m/s)\n    400.0,  # min exit temperature (K)\n    5.0,    # min flow rate (m³/s)\n    50.0,   # min plume rise (m)\n    50.0,   # PinG stack height (m)\n    0.01,   # PinG emissions threshold (kg/s)\n)\nclassified = classify_point_sources(point_emissions; criteria=criteria)","category":"section"},{"location":"elevpoint/#Stack-Grouping","page":"Elevated Source Identification","title":"Stack Grouping","text":"# Group similar stacks at same facility\ngrouped = group_stacks(point_emissions; height_bin=10.0, temp_bin=50.0)","category":"section"},{"location":"elevpoint/#Classification-Logic","page":"Elevated Source Identification","title":"Classification Logic","text":"A source is elevated if ANY of these criteria are met:\n\nStack height ≥ threshold\nExit velocity ≥ threshold\nExit temperature ≥ threshold\nFlow rate ≥ threshold\nAnalytical plume rise ≥ threshold\n\nAn elevated source is further classified as PinG if ALL PinG criteria are met:\n\nStack height ≥ PinG stack height threshold\nEmissions rate ≥ PinG emissions threshold (if set)","category":"section"},{"location":"elevpoint/#Emissions.ElevationCriteria","page":"Elevated Source Identification","title":"Emissions.ElevationCriteria","text":"ElevationCriteria\n\nThresholds for classifying point sources as surface, elevated, or Plume-in-Grid (PinG).\n\nAll values in SI units (meters, m/s, Kelvin).\n\nFields\n\nmin_stack_height::Float64: Minimum stack height for elevated (m)\nmin_exit_velocity::Float64: Minimum exit velocity for elevated (m/s)\nmin_exit_temperature::Float64: Minimum exit temperature for elevated (K)\nmin_flow_rate::Float64: Minimum volumetric flow rate for elevated (m³/s)\nmin_plume_rise::Float64: Minimum analytical plume rise for elevated (m)\nping_stack_height::Float64: Minimum stack height for PinG (m)\nping_emissions_threshold::Float64: Minimum emissions rate for PinG (kg/s)\n\n\n\n\n\n","category":"type"},{"location":"elevpoint/#Emissions.analytical_plume_rise","page":"Elevated Source Identification","title":"Emissions.analytical_plume_rise","text":"analytical_plume_rise(height, diam, temp, vel;\n    ambient_temp=293.15, ambient_wind=3.0) -> Float64\n\nCompute Briggs analytical plume rise for screening purposes.\n\nUses default meteorological values (ambient temperature 293.15 K, wind speed 3.0 m/s) as in SMOKE's Elevpoint program.\n\nArguments\n\nheight: Stack height (m)\ndiam: Stack diameter (m)\ntemp: Stack exit temperature (K)\nvel: Stack exit velocity (m/s)\nambient_temp: Ambient temperature (K), default 293.15\nambient_wind: Ambient wind speed (m/s), default 3.0\n\nReturns\n\nAnalytical plume rise in meters.\n\n\n\n\n\n","category":"function"},{"location":"elevpoint/#Emissions.classify_point_sources","page":"Elevated Source Identification","title":"Emissions.classify_point_sources","text":"classify_point_sources(point_emissions::DataFrame;\n    criteria::ElevationCriteria=DEFAULT_ELEVATION_CRITERIA) -> DataFrame\n\nClassify point sources as \"surface\", \"elevated\", or \"ping\" (Plume-in-Grid).\n\nA source is classified as \"elevated\" if it meets ANY of these criteria:\n\nStack height ≥ min_stack_height\nExit velocity ≥ min_exit_velocity\nExit temperature ≥ min_exit_temperature\nFlow rate ≥ min_flow_rate\nAnalytical plume rise ≥ min_plume_rise\n\nA source is further classified as \"ping\" if it meets ALL PinG criteria:\n\nStack height ≥ ping_stack_height\nEmissions rate ≥ ping_emissions_threshold (if threshold > 0)\n\nArguments\n\npoint_emissions::DataFrame: Must have columns :STKHGT (m), :STKDIAM (m), :STKTEMP (K), :STKVEL (m/s). May have :ANN_VALUE for PinG classification.\ncriteria: Elevation criteria thresholds.\n\nReturns\n\nA copy of point_emissions with added columns:\n\n:source_class (String): \"surface\", \"elevated\", or \"ping\"\n:analytical_plume_rise (Float64): Computed analytical plume rise (m)\n\n\n\n\n\n","category":"function"},{"location":"elevpoint/#Emissions.group_stacks","page":"Elevated Source Identification","title":"Emissions.group_stacks","text":"group_stacks(point_emissions::DataFrame;\n    height_bin::Float64=10.0, temp_bin::Float64=50.0) -> DataFrame\n\nGroup similar stacks at the same facility based on stack parameters.\n\nStacks at the same facility (same FIPS + facility ID or same coordinates) are grouped if their stack height and temperature are within the specified bin widths.\n\nArguments\n\npoint_emissions::DataFrame: Must have :STKHGT, :STKTEMP, :FIPS. May have :LONGITUDE, :LATITUDE for location-based grouping.\nheight_bin: Stack height bin width in meters (default 10.0).\ntemp_bin: Temperature bin width in Kelvin (default 50.0).\n\nReturns\n\nA copy of point_emissions with added column :stack_group (Int).\n\n\n\n\n\n","category":"function"},{"location":"biogenic/#Biogenic-Emissions","page":"Biogenic Emissions","title":"Biogenic Emissions","text":"","category":"section"},{"location":"biogenic/#Overview","page":"Biogenic Emissions","title":"Overview","text":"Biogenic emissions (isoprene, terpenes, etc.) from vegetation are computed using the BEIS (Biogenic Emission Inventory System) methodology, implementing the SMOKE Normbeis functionality.\n\nThe computation combines:\n\nLand cover data (BELD format)\nVegetation-specific emission factors\nTemperature and light response functions (Guenther, 1993)","category":"section"},{"location":"biogenic/#Usage","page":"Biogenic Emissions","title":"Usage","text":"","category":"section"},{"location":"biogenic/#Basic-Computation","page":"Biogenic Emissions","title":"Basic Computation","text":"using Emissions\n\n# Configure\nconfig = BiogenicConfig(\n    \"path/to/beld.csv\",\n    \"path/to/emission_factors.csv\",\n    :summer\n)\n\n# Define grid and meteorology\ngrid = NewGridIrregular(\"test\", 10, 10, \"EPSG:4326\", 0.5, 0.5, -80.0, 35.0)\ntemperature = fill(303.15, 100)  # K per grid cell\npar = fill(1000.0, 100)          # μmol/m²/s per grid cell\n\n# Compute\nbiogenic = compute_biogenic_emissions(config, grid, temperature, par)","category":"section"},{"location":"biogenic/#Combining-with-Anthropogenic-Emissions","page":"Biogenic Emissions","title":"Combining with Anthropogenic Emissions","text":"Biogenic output is compatible with merge_categories:\n\n# anthropogenic = process_emissions(...)  # gridded hourly\n# biogenic = compute_biogenic_emissions(...)\n# combined = merge_categories(anthropogenic, biogenic)","category":"section"},{"location":"biogenic/#Temperature-and-Light-Response","page":"Biogenic Emissions","title":"Temperature and Light Response","text":"","category":"section"},{"location":"biogenic/#Isoprene","page":"Biogenic Emissions","title":"Isoprene","text":"Temperature: Arrhenius-type function with optimum near 314 K\nLight: Hyperbolic PAR response (Guenther, 1993)\nBoth temperature and PAR adjustments are applied","category":"section"},{"location":"biogenic/#Terpenes-and-Other-BVOCs","page":"Biogenic Emissions","title":"Terpenes and Other BVOCs","text":"Temperature: Exponential response (β = 0.09 K⁻¹)\nLight: No light dependence (emissions are temperature-driven only)","category":"section"},{"location":"biogenic/#File-Formats","page":"Biogenic Emissions","title":"File Formats","text":"","category":"section"},{"location":"biogenic/#BELD-Land-Cover-File","page":"Biogenic Emissions","title":"BELD Land Cover File","text":"Comma-delimited: cell_index,land_use_type,fraction","category":"section"},{"location":"biogenic/#Emission-Factors-File","page":"Biogenic Emissions","title":"Emission Factors File","text":"Comma-delimited: land_use_type,species,summer_factor,winter_factor\n\nFactors are in μg/m²/hr at standard conditions (30°C, 1000 μmol/m²/s PAR).","category":"section"},{"location":"biogenic/#Emissions.BiogenicConfig","page":"Biogenic Emissions","title":"Emissions.BiogenicConfig","text":"BiogenicConfig\n\nConfiguration for biogenic emissions computation.\n\nFields\n\nland_use_file::String: Path to BELD land cover data file\nemission_factors_file::String: Path to emission factor data file\nseason::Symbol: Season (:summer or :winter) for factor selection\n\n\n\n\n\n","category":"type"},{"location":"biogenic/#Emissions.read_beld","page":"Biogenic Emissions","title":"Emissions.read_beld","text":"read_beld(filepath::AbstractString, grid::GridDef) -> DataFrame\n\nRead BELD (Biogenic Emissions Landcover Database) land cover data.\n\nLines starting with # are skipped. Each data line has comma-delimited fields: cell_index,land_use_type,fraction\n\nReturns\n\nA DataFrame with columns:\n\n:cell_index (Int): Grid cell index (1-based)\n:land_use_type (String): Land use category name\n:fraction (Float64): Fraction of cell covered by this land use (0-1)\n\n\n\n\n\n","category":"function"},{"location":"biogenic/#Emissions.read_emission_factors","page":"Biogenic Emissions","title":"Emissions.read_emission_factors","text":"read_emission_factors(filepath::AbstractString) -> DataFrame\n\nRead biogenic emission factor data (B3FAC/B4FAC format).\n\nLines starting with # are skipped. Each data line has comma-delimited fields: land_use_type,species,summer_factor,winter_factor\n\nEmission factors are in units of μg/m²/hr at standard conditions (30°C, 1000 μmol/m²/s PAR).\n\nReturns\n\nA DataFrame with columns:\n\n:land_use_type (String): Land use category name\n:species (String): Biogenic species name (e.g., \"ISOP\", \"TERP\", \"NO\")\n:summer_factor (Float64): Summer emission factor (μg/m²/hr)\n:winter_factor (Float64): Winter emission factor (μg/m²/hr)\n\n\n\n\n\n","category":"function"},{"location":"biogenic/#Emissions.temperature_adjustment","page":"Biogenic Emissions","title":"Emissions.temperature_adjustment","text":"temperature_adjustment(temp_K::Real, species::AbstractString) -> Float64\n\nCompute the Guenther (1993) temperature response factor for biogenic emissions.\n\nFor isoprene (\"ISOP\"), uses the Arrhenius-type function: γ_T = CT1 * exp(CT2 * (T - Ts) / (R * T * Ts)) / (1 + exp(CT3 * (T - TM) / (R * T * Ts)))\n\nFor terpenes and other species, uses an exponential function: γ_T = exp(β * (T - Ts))\n\nwhere Ts = 303.15 K is the standard temperature.\n\nArguments\n\ntemp_K: Temperature in Kelvin\nspecies: Species name (\"ISOP\" for isoprene, anything else for terpene-like response)\n\nReturns\n\nTemperature adjustment factor (dimensionless, 1.0 at standard conditions for terpenes).\n\n\n\n\n\n","category":"function"},{"location":"biogenic/#Emissions.light_adjustment","page":"Biogenic Emissions","title":"Emissions.light_adjustment","text":"light_adjustment(par::Real) -> Float64\n\nCompute the Guenther (1993) PAR response factor for isoprene emissions.\n\nγ_L = α * CL1 * PAR / sqrt(1 + α² * PAR²)\n\nwhere PAR is in μmol/m²/s, α = 0.0027, CL1 = 1.066.\n\nArguments\n\npar: Photosynthetically Active Radiation in μmol/m²/s\n\nReturns\n\nLight adjustment factor (dimensionless, 1.0 at PAR = 1000 μmol/m²/s).\n\n\n\n\n\n","category":"function"},{"location":"biogenic/#Emissions.compute_biogenic_emissions","page":"Biogenic Emissions","title":"Emissions.compute_biogenic_emissions","text":"compute_biogenic_emissions(config::BiogenicConfig, grid::GridDef,\n    temperature::Vector{Float64}, par::Vector{Float64}) -> DataFrame\n\nCompute gridded biogenic emissions for a single timestep.\n\nCombines land use data, emission factors, and meteorological adjustments to produce gridded biogenic emissions compatible with merge_categories.\n\nArguments\n\nconfig::BiogenicConfig: Configuration with paths and season.\ngrid::GridDef: Target grid definition.\ntemperature::Vector{Float64}: Temperature per grid cell (K). Length must equal grid.Nx * grid.Ny.\npar::Vector{Float64}: PAR per grid cell (μmol/m²/s). Length must equal grid.Nx * grid.Ny.\n\nReturns\n\nA DataFrame with columns:\n\n:grid_row (Int): Grid row index\n:grid_col (Int): Grid column index\n:pollutant (String): Biogenic species name\n:emission_rate (Float64): Emission rate (μg/m²/hr adjusted)\n\n\n\n\n\n","category":"function"},{"location":"validation/#Inventory-Validation","page":"Inventory Validation","title":"Inventory Validation","text":"","category":"section"},{"location":"validation/#Overview","page":"Inventory Validation","title":"Overview","text":"The inventory validation module provides quality assurance checks for emissions inventory data before processing. It detects common data issues such as duplicate records, out-of-range values, and missing required fields.\n\nThis implements functionality analogous to SMOKE's inventory QA checks, ensuring data integrity before the computationally expensive processing steps.","category":"section"},{"location":"validation/#Usage","page":"Inventory Validation","title":"Usage","text":"","category":"section"},{"location":"validation/#Basic-Validation","page":"Inventory Validation","title":"Basic Validation","text":"using Emissions, DataFrames\n\n# Create sample inventory data\nemissions = DataFrame(\n    FIPS = [\"36001\", \"36001\", \"36005\", \"06001\"],\n    SCC = [\"2103007000\", \"2103007000\", \"2103007001\", \"2103007000\"],\n    POLID = [\"NOX\", \"NOX\", \"VOC\", \"SO2\"],\n    ANN_VALUE = [100.0, 50.0, 200.0, -10.0]\n)\n\nresult = validate_inventory(emissions)\nprintln(\"Valid: \", result.valid)\nprintln(\"Warnings: \", result.warnings)\nprintln(\"Errors: \", result.errors)\nprintln(\"Duplicates found: \", result.n_duplicates)\nprintln(\"Range issues: \", result.n_range_issues)\nprintln(\"Missing fields: \", result.n_missing_fields)","category":"section"},{"location":"validation/#Individual-Checks","page":"Inventory Validation","title":"Individual Checks","text":"# Check for duplicates\ndups = check_duplicates(emissions)\nprintln(\"Duplicate groups: \", nrow(dups))\n\n# Check value ranges\nrange_issues = check_ranges(emissions)\nprintln(\"Range issues: \", nrow(range_issues))\n\n# Check completeness\nmissing_fields = check_completeness(emissions)\nprintln(\"Records with missing fields: \", nrow(missing_fields))","category":"section"},{"location":"validation/#Pipeline-Integration","page":"Inventory Validation","title":"Pipeline Integration","text":"Validation can be enabled in the processing pipeline via the do_validate keyword:\n\nresult = process_emissions(;\n    inventory_files = [(\"inventory.csv\", :nonpoint)],\n    grid = my_grid,\n    do_validate = true,  # Enable validation after aggregation\n    # ... other options\n)","category":"section"},{"location":"validation/#Emissions.ValidationResult","page":"Inventory Validation","title":"Emissions.ValidationResult","text":"ValidationResult\n\nResult of inventory validation checks.\n\nFields\n\nvalid::Bool: Whether the inventory passed all checks (no errors).\nwarnings::Vector{String}: Warning messages (non-fatal issues).\nerrors::Vector{String}: Error messages (fatal issues).\nn_duplicates::Int: Number of duplicate record groups found.\nn_range_issues::Int: Number of records with out-of-range values.\nn_missing_fields::Int: Number of records with missing required fields.\n\n\n\n\n\n","category":"type"},{"location":"validation/#Emissions.check_duplicates","page":"Inventory Validation","title":"Emissions.check_duplicates","text":"check_duplicates(emissions::DataFrame) -> DataFrame\n\nFind duplicate records in an emissions inventory based on (FIPS, SCC, POLID) groups.\n\nReturns a DataFrame containing only the duplicate records, with an additional :dup_count column indicating how many records share the same key. Returns an empty DataFrame if no duplicates are found.\n\n\n\n\n\n","category":"function"},{"location":"validation/#Emissions.check_ranges","page":"Inventory Validation","title":"Emissions.check_ranges","text":"check_ranges(emissions::DataFrame; max_value::Float64=1e12) -> DataFrame\n\nFlag records with negative, zero, or extreme ANN_VALUE values.\n\nReturns a DataFrame of flagged records with an additional :range_issue column describing the problem (:negative, :zero, or :extreme).\n\n\n\n\n\n","category":"function"},{"location":"validation/#Emissions.check_completeness","page":"Inventory Validation","title":"Emissions.check_completeness","text":"check_completeness(emissions::DataFrame;\n    required::Vector{Symbol}=[:FIPS, :SCC, :POLID, :ANN_VALUE]) -> DataFrame\n\nFlag records with missing or empty values in required fields.\n\nReturns a DataFrame of flagged records with an additional :missing_fields column listing which required fields are missing or empty.\n\n\n\n\n\n","category":"function"},{"location":"validation/#Emissions.validate_inventory","page":"Inventory Validation","title":"Emissions.validate_inventory","text":"validate_inventory(emissions::DataFrame) -> ValidationResult\n\nRun all validation checks on an emissions inventory DataFrame.\n\nCalls check_duplicates, check_ranges, and check_completeness, then aggregates results into a ValidationResult.\n\nReturns\n\nA ValidationResult with valid=true if there are no errors (missing required fields or negative values). Duplicates and zero/extreme values are reported as warnings.\n\n\n\n\n\n","category":"function"},{"location":"#Emissions","page":"Home","title":"Emissions","text":"Documentation for Emissions.","category":"section"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"For a complete walkthrough of the emissions processing workflow, see the Complete Tutorial. This tutorial demonstrates the entire workflow from raw EPA emissions data to gridded outputs using both synthetic examples and instructions for the full NEI dataset.\n\nFor detailed API documentation of all functions and types, see the API Reference.\n\n","category":"section"},{"location":"tutorial/#Complete-Tutorial","page":"Complete Tutorial","title":"Complete Tutorial","text":"This tutorial demonstrates the complete workflow for processing EPA National Emissions Inventory (NEI) data using Emissions.jl, from raw FF10 files to gridded, spatially-allocated outputs.","category":"section"},{"location":"tutorial/#Overview","page":"Complete Tutorial","title":"Overview","text":"The emissions processing workflow consists of several key steps:\n\nSetup: Configuration and data paths\nLoad: Read FF10 format emissions files\nAggregate: Combine and sum emissions by location and source\nFilter: Keep only known pollutants and apply quality filters\nSpatial Setup: Initialize spatial processing components\nGrid Reference: Assign spatial surrogates to emissions\nSpatial Allocation: Generate allocation matrices from shapefiles\nOutput: Write gridded emissions to shapefile\n\nThis tutorial shows two approaches: a synthetic data example for learning and testing, and instructions for processing the full NEI dataset.","category":"section"},{"location":"tutorial/#Synthetic-Data-Walkthrough","page":"Complete Tutorial","title":"Synthetic Data Walkthrough","text":"The following example demonstrates the complete workflow using synthetic data that can be run without downloading large datasets.","category":"section"},{"location":"tutorial/#Step-1:-Create-Synthetic-Emissions-Data","page":"Complete Tutorial","title":"Step 1: Create Synthetic Emissions Data","text":"The first step is to create (or load) emissions data in the FF10 format used by the EPA. FF10 nonpoint files have 45 columns including location identifiers (FIPS county codes), source classification codes (SCC), pollutant IDs, and annual emission values in tons/year.\n\nusing Emissions\nusing DataFrames\nusing CSV\nusing Printf\nusing Unitful\n\nsynthetic_data = DataFrame(\n    COUNTRY = [\"0\", \"0\", \"0\", \"0\"],\n    FIPS = [\"36001\", \"36001\", \"36005\", \"36005\"],\n    TRIBAL_CODE = [\"0\", \"0\", \"0\", \"0\"],\n    CENSUS_TRACT = [\"0\", \"0\", \"0\", \"0\"],\n    SHAPE_ID = [\"0\", \"0\", \"0\", \"0\"],\n    SCC = [\"2103007000\", \"2103007000\", \"2103007000\", \"2103007000\"],\n    EMIS_TYPE = [\"\", \"\", \"\", \"\"],\n    POLID = [\"NOX\", \"VOC\", \"NOX\", \"VOC\"],\n    ANN_VALUE = [150.5, 75.2, 200.1, 125.8],  # tons/year\n    ANN_PCT_RED = [0.0, 0.0, 0.0, 0.0],\n    CONTROL_IDS = [\"\", \"\", \"\", \"\"],\n    CONTROL_MEASURES = [\"\", \"\", \"\", \"\"],\n    CURRENT_COST = [0.0, 0.0, 0.0, 0.0],\n    CUMULATIVE_COST = [0.0, 0.0, 0.0, 0.0],\n    PROJECTION_FACTOR = [1.0, 1.0, 1.0, 1.0],\n    REG_CODES = [\"\", \"\", \"\", \"\"],\n    CALC_METHOD = [1, 1, 1, 1],\n    CALC_YEAR = [2019, 2019, 2019, 2019],\n    DATE_UPDATED = [\"\", \"\", \"\", \"\"],\n    DATA_SET_ID = [\"\", \"\", \"\", \"\"],\n    JAN_VALUE = [0.0, 0.0, 0.0, 0.0],\n    FEB_VALUE = [0.0, 0.0, 0.0, 0.0],\n    MAR_VALUE = [0.0, 0.0, 0.0, 0.0],\n    APR_VALUE = [0.0, 0.0, 0.0, 0.0],\n    MAY_VALUE = [0.0, 0.0, 0.0, 0.0],\n    JUN_VALUE = [0.0, 0.0, 0.0, 0.0],\n    JUL_VALUE = [0.0, 0.0, 0.0, 0.0],\n    AUG_VALUE = [0.0, 0.0, 0.0, 0.0],\n    SEP_VALUE = [0.0, 0.0, 0.0, 0.0],\n    OCT_VALUE = [0.0, 0.0, 0.0, 0.0],\n    NOV_VALUE = [0.0, 0.0, 0.0, 0.0],\n    DEC_VALUE = [0.0, 0.0, 0.0, 0.0],\n    JAN_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    FEB_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    MAR_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    APR_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    MAY_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    JUN_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    JUL_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    AUG_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    SEP_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    OCT_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    NOV_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    DEC_PCTRED = [0.0, 0.0, 0.0, 0.0],\n    COMMENT = [\"Synthetic example\", \"Synthetic example\", \"Synthetic example\", \"Synthetic example\"]\n)\n\nfirst(synthetic_data[!, [:FIPS, :SCC, :POLID, :ANN_VALUE]], 4)\n\nWe have 4 records: NOX and VOC emissions from two New York counties (Albany=36001, Bronx=36005), all from the same source category (SCC 2103007000, residential heating).","category":"section"},{"location":"tutorial/#Step-2:-Load-Emissions-with-FF10-Format-Validation","page":"Complete Tutorial","title":"Step 2: Load Emissions with FF10 Format Validation","text":"The FF10NonPointDataFrame constructor validates the data structure and automatically converts emission values from tons/year to kg/s (SI units):\n\nff10_data = FF10NonPointDataFrame(synthetic_data)\nprocessed_emis = ff10_data.df\n\nDataFrame(\n    Original_tons_yr = synthetic_data.ANN_VALUE,\n    Converted_kg_s = processed_emis.ANN_VALUE,\n    Ratio = processed_emis.ANN_VALUE ./ synthetic_data.ANN_VALUE\n)\n\nThe conversion factor is consistent across all records, as expected for a simple unit conversion from tons/year to kg/s.","category":"section"},{"location":"tutorial/#Step-3:-Aggregate-and-Filter-Emissions","page":"Complete Tutorial","title":"Step 3: Aggregate and Filter Emissions","text":"Next we group emissions by key fields and sum duplicate records, then filter to keep only known pollutants and map them to standardized names:\n\ngrouped_emis = combine(\n    groupby(processed_emis, [:POLID, :COUNTRY, :FIPS, :SCC]),\n    :ANN_VALUE => sum => :ANN_VALUE\n)\n\nknown_polls = filter(row -> haskey(Pollutants, row.POLID), grouped_emis)\nknown_polls[!, :POLID] = [Pollutants[p] for p in known_polls[!, :POLID]]\n\nknown_polls\n\nThe Pollutants dictionary maps FF10 pollutant codes (e.g., \"NOX\", \"VOC\") to standardized names used downstream.","category":"section"},{"location":"tutorial/#Step-4:-Set-Up-Spatial-Processing-Configuration","page":"Complete Tutorial","title":"Step 4: Set Up Spatial Processing Configuration","text":"Before we can assign emissions to grid cells, we need supporting data structures: a grid reference table that maps each (COUNTRY, FIPS, SCC) combination to a spatial surrogate code, a surrogate specification describing how to spatially distribute emissions, and a configuration object with file paths:\n\ngrid_ref = DataFrame(\n    COUNTRY = [\"USA\", \"USA\", \"USA\"],\n    FIPS = [\"36001\", \"36005\", \"00000\"],  # \"00000\" is a fallback surrogate\n    SCC = [\"2103007000\", \"2103007000\", \"2103007000\"],\n    Surrogate = [100, 100, 100]\n)\n\ngrid_ref\n\nsrg_spec = SurrogateSpec(\n    \"USA\",                    # Region\n    \"Population\",             # Name\n    100,                      # Code\n    \"population.shp\",         # DataShapefile\n    \"POP2019\",               # DataAttribute\n    \"area.shp\",              # WeightShapefile\n    \"Area-based allocation\",  # Details\n    String[],                # BackupSurrogateNames\n    [\"AREA\"],                # WeightColumns\n    [1.0],                   # WeightFactors\n    \"\",                      # FilterFunction\n    String[],                # MergeNames\n    Float64[]                # MergeMultipliers\n)\n\nprintln(\"Surrogate $(srg_spec.Code): $(srg_spec.Name)\")\nprintln(\"  Data shapefile: $(srg_spec.DataShapefile) [$(srg_spec.DataAttribute)]\")\nprintln(\"  Weight shapefile: $(srg_spec.WeightShapefile) [$(join(srg_spec.WeightColumns, \", \"))]\")\n\nconfig = Config(\n    [\"/tmp/synthetic_gridref.csv\"],      # f_gridRef\n    \"/tmp/synthetic_srgspec.csv\",        # SrgSpec\n    \"/tmp/shapefiles/\",                  # SrgShapefileDirectory\n    \"+proj=longlat +datum=WGS84\",        # InputSR\n    \"+proj=lcc +lat_1=33 +lat_2=45\",     # OutputSR\n    \"/tmp/synthetic_grid.txt\",           # GridFile\n    \"SyntheticGrid\",                     # GridName\n    \"/tmp/counties.shp\",                 # Counties\n    \"/tmp/output/\"                       # EmisShp\n)\n\nprintln(\"Grid name: $(config.GridName)\")\nprintln(\"Input projection: $(config.InputSR)\")\nprintln(\"Output projection: $(config.OutputSR)\")","category":"section"},{"location":"tutorial/#Step-5:-Assign-Spatial-Surrogates","page":"Complete Tutorial","title":"Step 5: Assign Spatial Surrogates","text":"We join the emissions data with the grid reference to assign each record a spatial surrogate code. The surrogate determines how emissions from a county are distributed across grid cells (e.g., proportional to population):\n\nemissions_with_surrogates = leftjoin(\n    known_polls,\n    grid_ref,\n    on = [:COUNTRY, :FIPS, :SCC]\n)\n\nemissions_with_surrogates\n\nAny rows with missing in the Surrogate column would need fallback handling. In real processing, these would be matched against FIPS=\"00000\" records which provide state-level default surrogates.\n\nunmatched = filter(row -> ismissing(row.Surrogate), emissions_with_surrogates)\nprintln(\"Unmatched emissions requiring fallback: $(nrow(unmatched))\")","category":"section"},{"location":"tutorial/#Step-6:-Key-Constants-and-Unit-Conversions","page":"Complete Tutorial","title":"Step 6: Key Constants and Unit Conversions","text":"Emissions.jl provides built-in unit conversion constants and a temperature conversion function used throughout the processing pipeline:\n\nDataFrame(\n    Conversion = [\"tons/year to kg/s\", \"tons/month to kg/s\", \"feet to meters\"],\n    Factor = [ustrip(tonperyear), ustrip(tonpermonth), ustrip(foot)]\n)\n\ntemps_f = [32.0, 68.0, 212.0]\nDataFrame(\n    Fahrenheit = temps_f,\n    Kelvin = [ustrip(kelvin(t)) for t in temps_f],\n    Description = [\"Freezing point\", \"Room temperature\", \"Boiling point\"]\n)\n\nThe Pollutants dictionary maps all supported FF10 pollutant codes to their standardized names:\n\nDataFrame(\n    FF10_Name = collect(keys(Pollutants)),\n    Standard_Name = collect(values(Pollutants))\n)","category":"section"},{"location":"tutorial/#Step-7:-Spatial-Processing-Overview","page":"Complete Tutorial","title":"Step 7: Spatial Processing Overview","text":"After surrogate assignment, the remaining spatial processing steps distribute emissions to grid cells using spatial surrogate data derived from shapefiles. Here is a summary of the workflow and its key functions:\n\nStep Function Description\nLoad shapefiles generate_data_sparse_matrices() Read population/area data\nWeight shapefiles generate_weight_sparse_matrices() Read surrogate weights\nGrid matrices generate_grid_sparse_matrices() Create target grid coverage\nSurrogate generation generate_countySurrogate() Compute normalized allocation fractions\nLocation indexing GetIndex() Find grid cells for each emission location\nFinal allocation recordToGrid() Distribute emissions to cells\nOutput writeEmis() Write final gridded emissions\n\nAn example of what the final gridded output looks like:\n\nDataFrame(\n    GridCell = [1, 1, 2, 2],\n    Pollutant = [\"NOX\", \"VOC\", \"NOX\", \"VOC\"],\n    EmissionRate_kg_s = [1.2e-6, 6.1e-7, 1.6e-6, 1.0e-6],\n    SourceCount = [2, 2, 2, 2],\n    County = [\"36001\", \"36001\", \"36005\", \"36005\"]\n)\n\nFor a fully executable example of spatial allocation with synthetic surrogates, see the Spatial Processing Pipeline page.","category":"section"},{"location":"tutorial/#Processing-the-Full-NEI-Dataset","page":"Complete Tutorial","title":"Processing the Full NEI Dataset","text":"For processing the complete EPA National Emissions Inventory, follow these steps:","category":"section"},{"location":"tutorial/#Step-1:-Download-NEI-Data","page":"Complete Tutorial","title":"Step 1: Download NEI Data","text":"# The full NEI dataset can be downloaded from EPA's website:\n# https://www.epa.gov/air-emissions-inventories/2019-national-emissions-inventory-nei-data\n\n# Example file structure for 2019 NEI:\nnei_base_url = \"https://gaftp.epa.gov/air/nei/2019/\"\nfile_downloads = [\n    \"nonpoint/2019v1_nonpoint_20210121_csv.zip\",\n    \"point/2019v1_point_20210121_csv.zip\",\n    \"nonroad/2019v1_nonroad_20210121_csv.zip\",\n    \"onroad/2019v1_onroad_20210121_csv.zip\"\n]\n\n# Download and extract files\nusing HTTP, ZipFile\nfor file in file_downloads\n    url = nei_base_url * file\n    local_path = joinpath(\"data\", \"nei2019\", basename(file))\n\n    # Download\n    println(\"Downloading: $url\")\n    HTTP.download(url, local_path)\n\n    # Extract ZIP file\n    zip_reader = ZipFile.Reader(local_path)\n    for file_info in zip_reader.files\n        # Extract CSV files to data directory\n        if endswith(file_info.name, \".csv\")\n            extracted_path = joinpath(\"data\", \"nei2019\", file_info.name)\n            open(extracted_path, \"w\") do io\n                write(io, read(file_info))\n            end\n            println(\"  Extracted: $(file_info.name)\")\n        end\n    end\n    close(zip_reader)\nend","category":"section"},{"location":"tutorial/#Step-2:-Set-Up-Real-Configuration","page":"Complete Tutorial","title":"Step 2: Set Up Real Configuration","text":"# Configure paths for full NEI processing\nreal_config = Config(\n    # Grid reference files (multiple regions)\n    [\n        \"data/spatial/gridref_usa_2019.csv\",\n        \"data/spatial/gridref_canada_2019.csv\",\n        \"data/spatial/gridref_mexico_2019.csv\"\n    ],\n\n    # Surrogate specification file\n    \"data/spatial/surrogate_specification_2019.csv\",\n\n    # Directory containing all spatial surrogate shapefiles\n    \"data/spatial/shapefiles/\",\n\n    # Input coordinate system (geographic coordinates)\n    \"+proj=longlat +datum=WGS84 +no_defs\",\n\n    # Output coordinate system (Lambert Conformal Conic for US modeling)\n    \"+proj=lcc +lat_1=33 +lat_2=45 +lat_0=40 +lon_0=-97 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\",\n\n    # Grid definition file (defines target modeling grid)\n    \"data/grids/inmap_conus_grid.txt\",\n\n    # Grid identifier\n    \"InMAP_CONUS\",\n\n    # County boundaries shapefile\n    \"data/spatial/shapefiles/tl_2019_us_county.shp\",\n\n    # Output directory for gridded emissions\n    \"output/nei2019_gridded/\"\n)","category":"section"},{"location":"tutorial/#Step-3:-Process-Full-Dataset-by-Sector","page":"Complete Tutorial","title":"Step 3: Process Full Dataset by Sector","text":"# Define readers for each emission sector\nreaders = Dict(\n    \"nonpoint\" => (f -> FF10NonPointDataFrame(CSV.read(f, DataFrame, comment=\"#\"))),\n    \"point\" => (f -> FF10PointDataFrame(CSV.read(f, DataFrame, comment=\"#\"))),\n    \"nonroad\" => (f -> FF10NonRoadDataFrame(CSV.read(f, DataFrame, comment=\"#\"))),\n    \"onroad\" => (f -> FF10OnRoadDataFrame(CSV.read(f, DataFrame, comment=\"#\")))\n)\n\n# Process each sector separately to manage memory\nall_emissions = DataFrame[]\n\nfor (sector, reader) in readers\n    println(\"Processing $sector emissions...\")\n\n    # Find all CSV files for this sector\n    sector_files = filter(f -> contains(f, sector) && endswith(f, \".csv\"),\n                         readdir(\"data/nei2019/\", join=true))\n\n    sector_emissions = DataFrame[]\n    for file in sector_files\n        println(\"  Reading: $(basename(file))\")\n        try\n            ff10_data = reader(file)\n            push!(sector_emissions, ff10_data.df)\n        catch e\n            println(\"    Warning: Error reading $file: $e\")\n        end\n    end\n\n    # Concatenate all files in this sector\n    if !isempty(sector_emissions)\n        sector_combined = vcat(sector_emissions...)\n        println(\"  $sector total: $(nrow(sector_combined)) records\")\n        push!(all_emissions, sector_combined)\n    end\nend\n\n# Combine all sectors\nprintln(\"Combining all emission sectors...\")\ncombined_emissions = vcat(all_emissions...)\nprintln(\"Total emissions: $(nrow(combined_emissions)) records\")","category":"section"},{"location":"tutorial/#Step-4:-Full-Spatial-Processing","page":"Complete Tutorial","title":"Step 4: Full Spatial Processing","text":"# Initialize spatial processing for the full domain\nsp, gd = setupSpatialProcessor(real_config)\n\n# Aggregate emissions by location and source characteristics\naggregated = combine(\n    groupby(combined_emissions, [:POLID, :COUNTRY, :FIPS, :SCC, :LON, :LAT]),\n    :ANN_VALUE => sum => :ANN_VALUE,\n    :STACK_HEIGHT => mean => :STACK_HEIGHT,  # For point sources\n    :STACK_DIAMETER => mean => :STACK_DIAMETER,\n    :STACK_TEMP => mean => :STACK_TEMP,\n    :STACK_FLOW => sum => :STACK_FLOW,\n    :STACK_VELOCITY => mean => :STACK_VELOCITY\n)\n\n# Filter to known pollutants and standardize names\nknown_emis = filter(row -> haskey(Pollutants, row.POLID), aggregated)\nknown_emis[!, :POLID] = [Pollutants[p] for p in known_emis[!, :POLID]]\n\n# Join with grid reference to assign surrogates\nemissions_with_surrogates = leftjoin(known_emis, sp.GridRef, on=[:COUNTRY, :FIPS, :SCC])\n\n# Handle fallback surrogates for unmatched emissions\nunmatched = filter(row -> ismissing(row.Surrogate), emissions_with_surrogates)\nif nrow(unmatched) > 0\n    # Try fallback with FIPS = \"00000\" (statewide surrogates)\n    fallback_ref = filter(row -> row.FIPS == \"00000\", sp.GridRef)\n\n    # Match unmatched emissions with fallback surrogates\n    unmatched_fallback = leftjoin(\n        select(unmatched, Not(:Surrogate)),\n        select(fallback_ref, [:COUNTRY, :SCC, :Surrogate => :FallbackSurrogate]),\n        on = [:COUNTRY, :SCC]\n    )\n    unmatched_fallback[!, :Surrogate] = unmatched_fallback[!, :FallbackSurrogate]\n    select!(unmatched_fallback, Not(:FallbackSurrogate))\n\n    # Combine matched and fallback-matched emissions\n    matched = filter(row -> !ismissing(row.Surrogate), emissions_with_surrogates)\n    final_emissions = vcat(matched, unmatched_fallback)\nelse\n    final_emissions = emissions_with_surrogates\nend\n\nprintln(\"Final emissions ready for spatial allocation: $(nrow(final_emissions)) records\")","category":"section"},{"location":"tutorial/#Step-5:-Generate-Full-Spatial-Allocation","page":"Complete Tutorial","title":"Step 5: Generate Full Spatial Allocation","text":"# Define processing domain bounds (full CONUS)\nconus_bounds = (\n    x_min = -130.0,  # Western boundary\n    x_max = -65.0,   # Eastern boundary\n    y_min = 20.0,    # Southern boundary\n    y_max = 55.0     # Northern boundary\n)\n\nresolution = 0.01  # ~1km resolution\n\n# Generate sparse matrices for all shapefiles used in surrogates\nprintln(\"Generating spatial allocation matrices...\")\n\nall_sparse_data = Dict()\nall_sparse_weight = Dict()\n\nfor spec in sp.SrgSpecs\n    println(\"Processing surrogate $(spec.Code): $(spec.Name)\")\n\n    # Generate data matrices\n    if !haskey(all_sparse_data, spec.DataShapefile)\n        data_matrices = generate_data_sparse_matrices(\n            conus_bounds.x_min, conus_bounds.x_max,\n            conus_bounds.y_min, conus_bounds.y_max,\n            resolution,\n            joinpath(real_config.SrgShapefileDirectory, spec.DataShapefile),\n            spec.DataAttribute\n        )\n        all_sparse_data[spec.DataShapefile] = data_matrices\n    end\n\n    # Generate weight matrices\n    if !haskey(all_sparse_weight, spec.WeightShapefile)\n        weight_matrices = generate_weight_sparse_matrices(\n            conus_bounds.x_min, conus_bounds.x_max,\n            conus_bounds.y_min, conus_bounds.y_max,\n            resolution,\n            joinpath(real_config.SrgShapefileDirectory, spec.WeightShapefile),\n            spec.WeightColumns[1];  # Use first weight column\n            Filter = spec.FilterFunction\n        )\n        all_sparse_weight[spec.WeightShapefile] = weight_matrices\n    end\nend","category":"section"},{"location":"tutorial/#Step-6:-Write-Final-Output","page":"Complete Tutorial","title":"Step 6: Write Final Output","text":"# Generate county surrogates for all combinations\ncounty_surrogates = Dict()\nfor spec in sp.SrgSpecs\n    key = (spec.DataShapefile, spec.WeightShapefile)\n    if !haskey(county_surrogates, key)\n        county_surrogates[key] = generate_countySurrogate(\n            all_sparse_data[spec.DataShapefile],\n            all_sparse_weight[spec.WeightShapefile]\n        )\n    end\nend\n\n# For each unique emission location, create spatial index\nunique_locations = unique(select(final_emissions, [:COUNTRY, :FIPS, :LON, :LAT]))\nlocation_indices = Dict()\n\nfor row in eachrow(unique_locations)\n    if !ismissing(row.LON) && !ismissing(row.LAT)\n        # Point source - use coordinates\n        location_key = (row.COUNTRY, row.FIPS, row.LON, row.LAT)\n        location_indices[location_key] = GetIndex(row.LON, row.LAT, gd)\n    else\n        # Area source - use county polygon\n        location_key = (row.COUNTRY, row.FIPS, \"COUNTY\")\n        county_poly = findCountyPolygon(real_config.Counties, row.FIPS)\n        if county_poly !== nothing\n            location_indices[location_key] = GetIndex(county_poly, gd)\n        end\n    end\nend\n\n# Apply spatial allocation and write output\nprintln(\"Writing final gridded emissions...\")\n\noutput_records = []\nfor row in eachrow(final_emissions)\n    if !ismissing(row.Surrogate)\n        # Find appropriate surrogate data\n        spec = find_surrogate_by_code(sp.SrgSpecs, row.Surrogate)\n        if spec !== nothing\n            # Get location index\n            if !ismissing(row.LON) && !ismissing(row.LAT)\n                location_key = (row.COUNTRY, row.FIPS, row.LON, row.LAT)\n            else\n                location_key = (row.COUNTRY, row.FIPS, \"COUNTY\")\n            end\n\n            if haskey(location_indices, location_key)\n                index_info = location_indices[location_key]\n\n                # Apply surrogate allocation\n                surrogate_key = (spec.DataShapefile, spec.WeightShapefile)\n                if haskey(county_surrogates, surrogate_key)\n                    surrogate_data = county_surrogates[surrogate_key]\n\n                    # Distribute emissions to grid cells\n                    allocated = recordToGrid(\n                        row.ANN_VALUE,\n                        index_info,\n                        get(surrogate_data, row.FIPS, nothing)\n                    )\n\n                    # Store results for output\n                    for (cell_idx, emission_amount) in pairs(allocated.nzval)\n                        push!(output_records, (\n                            grid_cell = cell_idx,\n                            pollutant = row.POLID,\n                            emission_kg_s = emission_amount,\n                            source_fips = row.FIPS,\n                            source_scc = row.SCC\n                        ))\n                    end\n                end\n            end\n        end\n    end\nend\n\n# Convert to DataFrame and write shapefile\noutput_df = DataFrame(output_records)\nwriteEmis(\n    joinpath(real_config.EmisShp, \"nei2019_gridded_emissions.shp\"),\n    gd,\n    output_df,\n    real_config.OutputSR,\n    \"Final gridded 2019 NEI emissions\"\n)\n\nprintln(\"Processing complete!\")\nprintln(\"Output written to: $(real_config.EmisShp)\")\nprintln(\"Total gridded emission records: $(nrow(output_df))\")","category":"section"},{"location":"tutorial/#Performance-Considerations","page":"Complete Tutorial","title":"Performance Considerations","text":"For processing the full NEI dataset (~50GB total):\n\nMemory: 32-64GB RAM recommended for full domain processing\nStorage: ~200GB for input data, intermediate files, and outputs\nProcessing Time: 4-8 hours for complete CONUS domain at 1km resolution\nParallelization: Consider geographic tiling or surrogate-based parallelization\n\nFor smaller domains or testing, use geographic bounds to subset the processing area and reduce computational requirements.","category":"section"},{"location":"tutorial/#Key-Functions-Reference","page":"Complete Tutorial","title":"Key Functions Reference","text":"","category":"section"},{"location":"tutorial/#FF10-Data-Loading","page":"Complete Tutorial","title":"FF10 Data Loading","text":"FF10NonPointDataFrame() - Area source emissions (45 columns)\nFF10PointDataFrame() - Point source emissions (77 columns)\nFF10NonRoadDataFrame() - Non-road mobile emissions (45 columns)\nFF10OnRoadDataFrame() - On-road mobile emissions (45 columns)","category":"section"},{"location":"tutorial/#Configuration-and-Setup","page":"Complete Tutorial","title":"Configuration and Setup","text":"Config() - Main configuration structure\nsetupSpatialProcessor() - Initialize spatial processing","category":"section"},{"location":"tutorial/#Spatial-Allocation","page":"Complete Tutorial","title":"Spatial Allocation","text":"generate_data_sparse_matrices() - Load data shapefiles\ngenerate_weight_sparse_matrices() - Load weight shapefiles\ngenerate_countySurrogate() - Create allocation surrogates\nGetIndex() - Map locations to grid cells\nrecordToGrid() - Distribute emissions to cells","category":"section"},{"location":"tutorial/#Output-and-Utilities","page":"Complete Tutorial","title":"Output and Utilities","text":"writeEmis() - Write final gridded shapefile\nfind_surrogate_by_code() - Look up surrogate specifications\nUnit conversion constants: tonperyear, tonpermonth, foot, kelvin()\nPollutant mapping: Pollutants dictionary","category":"section"}]
}
